{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-Learning-Lab-Guide.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 TensorFlow 2 Basics "
      ],
      "metadata": {
        "id": "9n2X6gV3Nl41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Introduction"
      ],
      "metadata": {
        "id": "5eLjA2GhNvZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 About This Lab"
      ],
      "metadata": {
        "id": "n69g_p8PN8vQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This experiment helps trainees understand the basic syntax of TensorFlow 2 by introducing a series of tensor operations of TensorFlow 2, including tensor creation, slicing, and indexing, tensor dimension modification, tensor arithmetic operations, and tensor sorting."
      ],
      "metadata": {
        "id": "WcJvqnXQOBdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 Objectives"
      ],
      "metadata": {
        "id": "VdiRscBmOGd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ElSz5n8Ol5PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon completion of this experiment, you will be able to:      \n",
        "-  Understand how to create a tensor.     \n",
        "-  Master the tensor slicing and indexing methods.\n",
        "-  Master the syntax for tensor dimension modification.\n",
        "-  Master arithmetic operations of tensors. \n",
        "-  Master the tensor sorting method.\n",
        "-  Dive deeper into Eager Execution and AutoGraph based on code."
      ],
      "metadata": {
        "id": "4CJBAimSOEry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Procedure"
      ],
      "metadata": {
        "id": "Xs2zGy8NONAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Tensors"
      ],
      "metadata": {
        "id": "YMbbrlbkgpyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, tensors are classified into constant tensors and variable tensors:    \n",
        "-  A defined constant tensor has an unchangeable value and dimension, and a defined variable tensor has a changeable value and an unchangeable dimension.\n",
        "-  In neural networks, variable tensors are generally used as matrices for storing weights and other information, and are a type of trainable data. Constant tensors can be used as variables for storing hyperparameters or other structured data."
      ],
      "metadata": {
        "id": "Z5xjX9VhgxuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.1 Importing TensorFlow"
      ],
      "metadata": {
        "id": "EHKD7Cjyg-4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "1QmuyivRhDIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.2 Tensor Creation"
      ],
      "metadata": {
        "id": "BA2ocZoLhKGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.2.1 Creating a Constant Tensor"
      ],
      "metadata": {
        "id": "UJACI4klj9Gm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common methods for creating a constant tensor include:    \n",
        "-  `tf.constant()`: creates a constant tensor.\n",
        "-  `tf.zeros()`, `tf.zeros_like()`, `tf.ones()`, and `tf.ones_like()`: creates an all-zero or all-one constant tensor.\n",
        "-  `tf.fill()`: creates a tensor with a user-defined value.\n",
        "-  `tf.random`: creates a tensor with a known distribution.\n",
        "-  Create a list object by using NumPy, and then convert the list object into a tensor by using `tf.convert_to_tensor`."
      ],
      "metadata": {
        "id": "Pr3Xx8uSkFfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 `tf.constant()`    \n",
        "`tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)`:   \n",
        "-  `value`: value\n",
        "-  `dtype`: data type\n",
        "-  `shape`: tensor type\n",
        "-  `name`: constant name\n",
        "-  `verify_shape`: Boolean value, used to verify the shape of a value. The default value is `False`. If `verify_shape` is set to `True`, the system checks whether the shape of a value is consistent with the shape. If they are inconsistent, the system reports an error."
      ],
      "metadata": {
        "id": "z98WCyBmkDCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "const_a = tf.constant([[1, 2, 3, 4]],shape=[2,2], dtype=tf.float32) #Create a 2x2 matrix with values 1, 2, 3, and 4. \n",
        "const_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS9LuJU6k2ug",
        "outputId": "ddf8808c-9a07-4def-c37a-77aaf481fecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[1., 2.],\n",
              "       [3., 4.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#View common attributes. \n",
        "print(\"value of the constant const_a:\", const_a.numpy()) \n",
        "print(\"data type of the constant const_a:\", const_a.dtype) \n",
        "print(\"shape of the constant const_a:\", const_a.shape) \n",
        "print(\"name of the device that is to generate the constant const_a:\", const_a.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8lOmKdkk6xA",
        "outputId": "6ed576e0-a385-471e-cce3-371da8a7cf76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of the constant const_a: [[1. 2.]\n",
            " [3. 4.]]\n",
            "data type of the constant const_a: <dtype: 'float32'>\n",
            "shape of the constant const_a: (2, 2)\n",
            "name of the device that is to generate the constant const_a: /job:localhost/replica:0/task:0/device:CPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 `tf.zeros()`, `tf.zeros_like()`, `tf.ones()`, and `tf.ones_like()`       \n",
        "Usages of `tf.ones()` and `tf.ones_like()` are similar to those of `tf.zeros()` and `tf.zeros_like()`. Therefore, the following describes only the usages of `tf.ones()` and `tf.ones_like()`.    \n",
        "\n",
        "Create a constant with the value `0`. `tf.zeros(shape, dtype=tf.float32, name=None)`:    \n",
        "-  shape: tensor shape.\n",
        "-  dtype: data type.\n",
        "-  name: specifies the template name.       \n"
      ],
      "metadata": {
        "id": "Ck9SU6zhlL94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_b = tf.zeros(shape=[2, 3], dtype=tf.int32) #Create a 2x3 matrix with all values being 0.\n",
        "zeros_b"
      ],
      "metadata": {
        "id": "xUxavezSlPek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639cca2f-14b6-4fd9-b44e-4eb3968eb485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[0, 0, 0],\n",
              "       [0, 0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tensor whose value is `0` based on the input tensor, with its shape being the same as that of the input tensor:     \n",
        " `tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)`:\n",
        "-  input_tensor: tensor.\n",
        "-  dtype: data type.\n",
        "-  name: tensor name.\n",
        "-  optimize: indicates whether optimization is enabled."
      ],
      "metadata": {
        "id": "QWOLDAz6lOFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "const_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH8MLkWaplUW",
        "outputId": "a9db875c-6036-42c7-944b-5a616d05a9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[1., 2.],\n",
              "       [3., 4.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_like_c = tf.zeros_like(const_a) #View generated data. \n",
        "zeros_like_c.numpy()\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLV0sjEwWnwY",
        "outputId": "aef7d0ea-fc0a-40be-979c-89e7b6e56f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 `tf.fill()`    \n",
        "Create a tensor and fill it with a specific value.     \n",
        "`tf.fill(dims, value, name=None)`:     \n",
        "-  dims: tensor shape, which is the same as shape above.\n",
        "-  value: tensor value.\n",
        "-  name: tensor name."
      ],
      "metadata": {
        "id": "66QL2qoSXBeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fill_d = tf.fill([3,3], 8) #3x3 matrix. The element value is 8. #View the data. \n",
        "fill_d.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PbPXvMTXTb6",
        "outputId": "6f08a94a-81a3-4c78-e013-27820b7cec2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8, 8, 8],\n",
              "       [8, 8, 8],\n",
              "       [8, 8, 8]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 `tf.random`     \n",
        "This module is used to generate a tensor with a specific distribution. Common methods in this module include `tf.random.uniform()`, `tf.random.normal()`, and `tf.random.shuffle()`. The following describes how to use `tf.random.normal()`.    \n",
        "Create a tensor that conforms to a normal distribution.   \n",
        "`tf.random.normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32,seed=None, name=None)`:     \n",
        "-  shape: data shape.\n",
        "-  mean: mean value with a Gaussian distribution.\n",
        "-  stddev: standard deviation with a Gaussian distribution.\n",
        "-  dtype: data type.\n",
        "-  seed: random seed.\n",
        "-  name: tensor name."
      ],
      "metadata": {
        "id": "Ym3O55V5XTQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_e = tf.random.normal([5,5],mean=0,stddev=1.0, seed = 1) #View created data. \n",
        "random_e.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oThK3eEhXTFp",
        "outputId": "930784d4-2e7e-4f68-df74-0b29e19b0861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.32386488,  0.99133694,  0.14024267,  1.2573972 ,  0.09992335],\n",
              "       [ 0.18983224, -0.28711194, -1.7413595 ,  1.8718754 , -2.0104504 ],\n",
              "       [-1.4673029 , -1.2721989 , -0.7803738 ,  0.94073033, -0.06164822],\n",
              "       [-2.0842526 ,  0.61423135, -1.451092  , -0.88693523, -0.96740866],\n",
              "       [ 0.94831836, -0.6974499 ,  0.5391437 , -0.52970064, -2.0105364 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 Creating a list object by using NumPy, and then convert the list object into a tensor by using `tf.convert_to_tensor`.    \n",
        "    \n",
        "This method can convert a given value into a tensor. `tf.convert_to_tensor` can be used to convert a Python data type into a tensor data type available to TensorFlow.    \n",
        "    \n",
        "`tf.convert_to_tensor(value,dtype=None,dtype_hint=None,name=None)`:\n",
        "-  value: value to be converted.\n",
        "-  dtype: data type of the tensor.\n",
        "-  dtype_hint: optional element type for the returned tensor, used when dtype is set to `None`. In some cases, a caller may not consider dtype when calling `tf.convert_to_tensor`. Therefore, dtype_hint can be used as a preference.    "
      ],
      "metadata": {
        "id": "cWPtoujUW0f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a list. \n",
        "list_f = [1,2,3,4,5,6] \n",
        "#View the data type. \n",
        "type(list_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0ZpX_s9X_Vo",
        "outputId": "9b6d634b-6c79-442c-9ce6-f38c73493f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f = tf.convert_to_tensor(list_f, dtype=tf.float32) \n",
        "tensor_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV7L9DDXX_mw",
        "outputId": "b3ba6966-c5a1-47d5-a38c-af553a28c493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.2.2 Creating a Variable Tensor"
      ],
      "metadata": {
        "id": "SAg9o4PQX_2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, variables are operated by using the `tf.Variable` class. `tf.Variable` indicates a tensor. The value of `tf.Variable` can be changed by running an arithmetic operation on `tf.Variable`. Variable values can be read and changed."
      ],
      "metadata": {
        "id": "n3u-aTAaYADo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a variable. Only the initial value needs to be provided. \n",
        "var_1 = tf.Variable(tf.ones([2,3])) \n",
        "var_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l08AkywJYAjk",
        "outputId": "2d69f581-01d0-43a6-d1ae-77cd65aa3e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the variable value. \n",
        "print(\"Value of the variable var_1:\",var_1.read_value()) \n",
        "#Assign a variable value. \n",
        "var_value_1=[[1,2,3],[4,5,6]] \n",
        "var_1.assign(var_value_1) \n",
        "print(\"Value of the variable var_1 after the assignment:\",var_1.read_value())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDhRFRs1YBM8",
        "outputId": "b66952ba-30bf-40fa-9fbc-773636b53cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of the variable var_1: tf.Tensor(\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
            "Value of the variable var_1 after the assignment: tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.3 Tensor Slicing and Indexing"
      ],
      "metadata": {
        "id": "jG8izo6jYBdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.3.1 Slicing"
      ],
      "metadata": {
        "id": "-rEsvUsqYBqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor slicing methods include:    \n",
        "-   [start: End]: extracts a data slice from the start position to the end position of the tensor.\n",
        "-   [start:end:step] or [::step]: extracts a data slice at an interval of step from the start position to the end position of the tensor.\n",
        "-   [::-1]: slices data from the last element.\n",
        "-   '...': indicates a data slice of any length."
      ],
      "metadata": {
        "id": "FVC7Lo8dZPug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a 4-dimensional tensor. The tensor contains four images. The size of each image is 100 x 100 x 3. \n",
        "tensor_h = tf.random.normal([4,100,100,3])\n",
        "tensor_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nknK6s50O9SL",
        "outputId": "a0c45c27-ab2d-4ee0-fef7-afa7aa897c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=\n",
              "array([[[[-8.80348861e-01,  2.71405280e-01,  9.06207204e-01],\n",
              "         [ 5.93119740e-01,  6.82946861e-01, -2.47171447e-01],\n",
              "         [-6.65472150e-01,  2.81757998e+00,  6.49745345e-01],\n",
              "         ...,\n",
              "         [ 8.71333539e-01,  8.99664104e-01, -8.29841554e-01],\n",
              "         [ 1.13124812e+00,  5.36805332e-01, -1.40769601e+00],\n",
              "         [-1.37473714e+00, -1.72108233e+00,  3.42596382e-01]],\n",
              "\n",
              "        [[ 1.43209505e+00, -5.78843296e-01, -3.66053879e-01],\n",
              "         [ 1.28983891e+00,  1.46318388e+00,  3.70568961e-01],\n",
              "         [ 5.07189989e-01,  1.17345369e+00, -1.17389989e+00],\n",
              "         ...,\n",
              "         [-1.01769853e+00, -1.91461515e+00, -3.12233388e-01],\n",
              "         [-1.49731266e+00, -1.07522392e+00, -1.10670829e+00],\n",
              "         [ 1.12240575e-01,  3.23153138e-01, -9.59781528e-01]],\n",
              "\n",
              "        [[-1.35504651e+00, -1.17648113e+00, -3.99530649e-01],\n",
              "         [-2.08420992e+00, -1.06119335e+00, -1.81732082e+00],\n",
              "         [ 2.16140652e+00, -1.00878753e-01, -2.55770758e-02],\n",
              "         ...,\n",
              "         [-4.04274523e-01, -1.27282572e+00,  5.75866044e-01],\n",
              "         [ 7.43096709e-01,  9.10562694e-01,  1.00143802e+00],\n",
              "         [-8.66966099e-02, -1.09531105e+00, -6.69030070e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.43014300e-01, -1.35098109e-02, -3.22903454e-01],\n",
              "         [-8.52823138e-01,  9.50612843e-01, -1.05394185e+00],\n",
              "         [-2.21011668e-01, -8.63013744e-01,  1.05244565e+00],\n",
              "         ...,\n",
              "         [-4.93951231e-01, -1.65642166e+00, -1.28688467e+00],\n",
              "         [ 2.18934923e-01,  9.45915699e-01, -4.07542735e-01],\n",
              "         [ 1.94882131e+00, -7.77700841e-01, -2.00122878e-01]],\n",
              "\n",
              "        [[-5.47967553e-02, -5.46596348e-01, -2.30614996e+00],\n",
              "         [ 8.46078515e-01,  6.95690095e-01,  6.56767666e-01],\n",
              "         [-2.45907173e-01,  7.17947960e-01, -5.78346737e-02],\n",
              "         ...,\n",
              "         [-7.07010746e-01, -4.35612321e-01, -1.12184119e+00],\n",
              "         [-1.91474819e+00,  3.50618094e-01,  1.21325696e+00],\n",
              "         [ 6.97672486e-01,  7.83810079e-01,  9.99754012e-01]],\n",
              "\n",
              "        [[-4.33989406e-01,  1.65746891e+00,  1.12178361e+00],\n",
              "         [-1.35984969e+00, -5.06404400e-01, -9.71680403e-01],\n",
              "         [ 2.06416264e-01, -5.52895308e-01, -2.13678050e+00],\n",
              "         ...,\n",
              "         [-6.28782928e-01,  1.14001262e+00, -4.95065510e-01],\n",
              "         [-2.32967064e-01,  7.18582034e-01,  7.93163955e-01],\n",
              "         [-7.63715863e-01,  6.88833237e-01,  9.33579147e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 1.28478277e+00, -2.46135578e-01,  7.63266087e-01],\n",
              "         [ 8.40199888e-01,  9.68266785e-01, -1.93278158e+00],\n",
              "         [-2.09653950e+00,  8.09427738e-01,  2.53316551e-01],\n",
              "         ...,\n",
              "         [ 7.27030933e-01, -4.74542752e-02,  8.99164498e-01],\n",
              "         [-8.15167308e-01,  4.26037997e-01, -6.86205089e-01],\n",
              "         [-4.67402607e-01, -2.35188913e+00, -2.83307910e-01]],\n",
              "\n",
              "        [[ 1.17288983e+00,  2.87962437e-01, -2.30707693e+00],\n",
              "         [-9.54468310e-01,  1.18314445e+00, -3.71690601e-01],\n",
              "         [ 1.45311785e+00, -1.12493455e+00, -2.05835223e-01],\n",
              "         ...,\n",
              "         [-4.36204791e-01,  7.51799226e-01,  7.72282302e-01],\n",
              "         [ 1.52221513e+00,  1.45522368e+00, -2.42574573e+00],\n",
              "         [-8.43710303e-01, -1.30115700e+00, -2.13285074e-01]],\n",
              "\n",
              "        [[-1.56356764e+00,  1.09605205e+00,  7.79315650e-01],\n",
              "         [-1.45281017e+00,  1.00318074e+00,  1.51921701e+00],\n",
              "         [ 1.42164469e+00,  3.23041707e-01,  6.56866014e-01],\n",
              "         ...,\n",
              "         [ 5.77209651e-01,  4.46495414e-01,  1.57666278e+00],\n",
              "         [-2.78246105e-01, -4.36549395e-01,  5.06283343e-01],\n",
              "         [ 5.07108450e-01,  1.08285439e+00,  4.25233424e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.78322330e-01,  8.77250373e-01, -7.05790937e-01],\n",
              "         [-4.01810259e-01, -4.60318238e-01,  2.78439224e-01],\n",
              "         [ 1.44627213e+00, -1.52383819e-01, -1.74593019e+00],\n",
              "         ...,\n",
              "         [ 1.31823853e-01,  9.76027429e-01,  3.30149770e-01],\n",
              "         [-2.89563447e-01, -3.92848730e+00, -3.17607373e-01],\n",
              "         [-1.43979311e+00,  2.10246108e-02, -3.12485874e-01]],\n",
              "\n",
              "        [[ 7.32896268e-01,  2.05464196e+00,  4.33212437e-04],\n",
              "         [ 1.37381685e+00, -6.49697185e-01,  1.08988702e+00],\n",
              "         [-4.28532809e-01, -1.50749922e+00, -2.40121388e+00],\n",
              "         ...,\n",
              "         [-2.34527612e+00,  4.20351326e-01,  9.06257272e-01],\n",
              "         [ 2.94619463e-02, -3.18071425e-01,  7.21470952e-01],\n",
              "         [-6.40402734e-01,  1.61624873e+00, -1.21447873e+00]],\n",
              "\n",
              "        [[-1.60136342e+00, -4.40431774e-01,  7.21037328e-01],\n",
              "         [-5.87926712e-03,  2.34594393e+00,  2.28388891e-01],\n",
              "         [-1.71428645e+00,  1.72451407e-01, -4.64472890e-01],\n",
              "         ...,\n",
              "         [-1.75712121e+00, -7.48715997e-01, -6.81563854e-01],\n",
              "         [-4.45661731e-02,  3.16094249e-01,  7.54296547e-03],\n",
              "         [-1.42325044e-01, -1.05170894e+00,  5.19285917e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 2.81874478e-01, -2.10300732e+00, -1.66421509e+00],\n",
              "         [-3.10557127e-01,  4.90045594e-03, -5.76574266e-01],\n",
              "         [-2.62086451e-01,  4.77945209e-01, -2.28244007e-01],\n",
              "         ...,\n",
              "         [ 2.02324963e+00, -1.37567091e+00,  1.99186072e-01],\n",
              "         [-1.30328071e+00,  3.13517272e-01, -3.01323026e-01],\n",
              "         [-6.89406753e-01, -1.33035195e+00, -1.13187575e+00]],\n",
              "\n",
              "        [[ 8.05322289e-01,  8.56892765e-01, -1.36488557e+00],\n",
              "         [ 5.66866219e-01, -2.06711388e+00,  1.88268736e-01],\n",
              "         [-1.43608227e-01, -1.03252268e+00, -1.10530627e+00],\n",
              "         ...,\n",
              "         [ 1.25418317e+00, -1.62971830e+00,  7.80748487e-01],\n",
              "         [-2.03992772e+00,  1.97856333e-02,  7.78273821e-01],\n",
              "         [-7.83819795e-01, -2.59416819e-01,  8.22688401e-01]],\n",
              "\n",
              "        [[ 4.78260398e-01, -3.73081356e-01, -4.84535098e-01],\n",
              "         [-2.73760766e-01,  7.24192619e-01, -1.04123688e+00],\n",
              "         [ 2.88639575e-01,  8.94188523e-01, -1.42694533e+00],\n",
              "         ...,\n",
              "         [-7.03774929e-01, -1.71176970e+00,  1.11418307e+00],\n",
              "         [-4.73176502e-02,  3.29967022e-01, -2.28434354e-02],\n",
              "         [ 1.05863750e+00, -5.53700566e-01,  2.39426285e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-4.42917258e-01,  9.04736578e-01, -1.10596813e-01],\n",
              "         [-2.67283463e+00, -6.24142647e-01, -3.64273727e-01],\n",
              "         [-5.92475533e-02,  2.26363182e+00,  2.13148385e-01],\n",
              "         ...,\n",
              "         [-2.07086965e-01, -3.60121936e-01, -1.59272170e+00],\n",
              "         [ 3.52991968e-01, -5.10824680e-01, -1.07964516e+00],\n",
              "         [-6.40307307e-01,  1.10639524e+00, -1.55664623e+00]],\n",
              "\n",
              "        [[-8.71032298e-01,  1.49037659e+00,  1.58307344e-01],\n",
              "         [-1.06320012e+00, -3.72965753e-01,  2.32485723e+00],\n",
              "         [ 7.15844810e-01,  1.50187314e-03, -1.73038319e-01],\n",
              "         ...,\n",
              "         [ 4.82787967e-01, -5.55242956e-01,  6.39505744e-01],\n",
              "         [ 1.27841055e+00,  1.63375691e-01, -2.57477373e-01],\n",
              "         [-2.01457405e+00, -1.13114297e+00,  8.73403311e-01]],\n",
              "\n",
              "        [[ 3.73390794e-01,  2.69634604e-01,  2.41413653e-01],\n",
              "         [-5.14540493e-01, -1.23153353e+00, -8.12080622e-01],\n",
              "         [-9.14992273e-01, -8.29972327e-01,  1.03508186e+00],\n",
              "         ...,\n",
              "         [ 4.62556809e-01,  4.54468340e-01,  3.84352684e-01],\n",
              "         [-2.21953437e-01,  1.69866413e-01, -9.25756097e-01],\n",
              "         [ 1.52992058e+00,  4.98951703e-01,  2.00178432e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 3.20220813e-02, -6.58975720e-01, -7.99338222e-01],\n",
              "         [ 3.72260094e-01,  1.79697621e+00, -1.47552681e+00],\n",
              "         [-2.41523072e-01,  2.96367288e-01,  3.29055876e-01],\n",
              "         ...,\n",
              "         [-1.00517547e+00,  1.60214972e+00, -7.39147067e-01],\n",
              "         [ 1.09214759e+00,  1.54992139e+00, -8.94285798e-01],\n",
              "         [-2.62214929e-01,  4.39197391e-01,  1.51579189e+00]],\n",
              "\n",
              "        [[ 3.50333333e-01,  5.38667105e-02,  1.54839277e+00],\n",
              "         [ 1.36311042e+00,  2.55138725e-01,  3.18276763e-01],\n",
              "         [-4.69795734e-01,  4.61675674e-01, -1.11373043e+00],\n",
              "         ...,\n",
              "         [-5.99532187e-01, -2.07754850e+00, -2.08721086e-01],\n",
              "         [-2.47637677e+00, -1.14004993e+00, -1.08890581e+00],\n",
              "         [ 4.57735509e-01,  1.18241596e+00, -4.71124709e-01]],\n",
              "\n",
              "        [[ 7.89984539e-02,  5.89958489e-01,  1.32196140e+00],\n",
              "         [ 1.19241923e-01, -1.11930239e+00,  5.66065051e-02],\n",
              "         [-1.41178894e+00,  5.60370870e-02, -6.00891531e-01],\n",
              "         ...,\n",
              "         [-7.30165839e-01, -4.46494609e-01, -1.56124151e+00],\n",
              "         [ 1.12571466e+00, -7.74870515e-01, -7.58526802e-01],\n",
              "         [ 4.38942611e-01, -1.35078681e+00, -1.15244234e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.06279659e+00, -1.28163433e+00, -1.84500825e+00],\n",
              "         [ 1.43440366e+00,  5.97340345e-01, -1.43251646e+00],\n",
              "         [-1.13914371e-01, -2.33217978e+00,  1.22702944e+00],\n",
              "         ...,\n",
              "         [-2.17943668e-01,  1.29608023e+00,  4.87404138e-01],\n",
              "         [-6.49404228e-01,  8.44438553e-01,  1.67352214e-01],\n",
              "         [ 1.91914424e-01, -1.20439552e-01, -7.07876623e-01]],\n",
              "\n",
              "        [[-9.73102391e-01,  1.43720508e+00, -1.98246038e+00],\n",
              "         [-8.86574805e-01, -6.35249853e-01,  1.23170722e+00],\n",
              "         [-3.21114250e-02,  7.70276189e-02, -2.20390767e-01],\n",
              "         ...,\n",
              "         [-3.11490625e-01, -5.37272811e-01,  8.43696535e-01],\n",
              "         [-1.02907372e+00, -1.26317871e+00,  1.27718556e+00],\n",
              "         [-1.52875856e-01, -5.26754320e-01,  5.45374036e-01]],\n",
              "\n",
              "        [[ 1.52581322e+00,  2.61611462e-01, -9.16973948e-01],\n",
              "         [ 1.97658730e+00, -9.98274207e-01,  5.86047471e-01],\n",
              "         [ 1.20567167e+00, -5.40087521e-01,  1.13369338e-01],\n",
              "         ...,\n",
              "         [-8.09189379e-01,  1.12123764e+00,  8.81230712e-01],\n",
              "         [-7.93019593e-01, -1.50294993e-02,  1.02733262e-01],\n",
              "         [ 5.43214381e-01,  9.25297499e-01,  8.07737350e-01]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the first image. \n",
        "tensor_h[0,:,:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAwRT3x-PHvM",
        "outputId": "ebca1d94-c3ad-4914-90e7-134baa455393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
              "array([[[ 2.0084465 , -2.3842397 ,  0.56350225],\n",
              "        [-0.22519012, -1.467062  ,  1.2867384 ],\n",
              "        [ 0.22692962, -1.8108065 , -0.3790379 ],\n",
              "        ...,\n",
              "        [-0.2686914 ,  0.9871089 ,  0.89998364],\n",
              "        [ 0.15595573,  0.40947148, -0.38696405],\n",
              "        [-0.0596903 , -0.8417322 ,  0.27858144]],\n",
              "\n",
              "       [[ 0.74453855, -0.7166861 , -0.87763757],\n",
              "        [-0.22609983, -0.38828808,  2.002849  ],\n",
              "        [-0.3537504 ,  0.44429556,  0.03500603],\n",
              "        ...,\n",
              "        [-0.19678767, -2.9079275 , -0.16309987],\n",
              "        [ 0.35830724,  0.15009251,  1.0155056 ],\n",
              "        [ 0.94981146,  0.0205699 , -1.1123472 ]],\n",
              "\n",
              "       [[ 0.6640408 , -1.8556162 , -0.36464202],\n",
              "        [ 0.14545   ,  1.1587137 ,  0.14326619],\n",
              "        [ 2.929728  , -0.9377867 ,  0.09968437],\n",
              "        ...,\n",
              "        [-0.9501617 ,  0.57695997,  1.7569122 ],\n",
              "        [ 0.8567236 ,  1.501124  , -1.2900442 ],\n",
              "        [-0.31652054, -0.95529073, -2.7000732 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.34208766, -0.22550887,  0.27934602],\n",
              "        [-1.2576056 ,  1.2092503 , -0.8549812 ],\n",
              "        [ 1.0419973 , -2.3677397 , -0.8147056 ],\n",
              "        ...,\n",
              "        [ 0.36284995,  0.48161316,  0.06349012],\n",
              "        [ 0.98407686,  1.1757438 ,  0.7150653 ],\n",
              "        [-1.7535636 ,  0.08025788, -1.39991   ]],\n",
              "\n",
              "       [[-0.47392303,  1.5250245 , -0.2579051 ],\n",
              "        [ 0.58722043,  0.60294855,  0.71258974],\n",
              "        [-1.2147799 ,  0.8108134 ,  1.9464319 ],\n",
              "        ...,\n",
              "        [-0.64686996,  0.7635501 , -0.57517856],\n",
              "        [-1.4359707 , -2.218749  ,  0.26840273],\n",
              "        [ 1.8579803 ,  1.3958024 , -0.8683945 ]],\n",
              "\n",
              "       [[ 1.9146159 ,  1.4838451 ,  0.23851646],\n",
              "        [ 0.17559691, -1.5608926 , -0.3723852 ],\n",
              "        [-0.4916337 , -0.7309565 , -0.65572536],\n",
              "        ...,\n",
              "        [ 1.3431171 , -0.98677385,  2.8708825 ],\n",
              "        [-0.5245141 ,  1.4790332 ,  1.5955522 ],\n",
              "        [-0.34914663,  0.14998667,  0.7894867 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract one slice at an interval of two images. \n",
        "tensor_h[::2,...]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JockjOInPLkA",
        "outputId": "ae21118b-9c86-4712-9e7a-6540680ef128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 100, 100, 3), dtype=float32, numpy=\n",
              "array([[[[-8.80348861e-01,  2.71405280e-01,  9.06207204e-01],\n",
              "         [ 5.93119740e-01,  6.82946861e-01, -2.47171447e-01],\n",
              "         [-6.65472150e-01,  2.81757998e+00,  6.49745345e-01],\n",
              "         ...,\n",
              "         [ 8.71333539e-01,  8.99664104e-01, -8.29841554e-01],\n",
              "         [ 1.13124812e+00,  5.36805332e-01, -1.40769601e+00],\n",
              "         [-1.37473714e+00, -1.72108233e+00,  3.42596382e-01]],\n",
              "\n",
              "        [[ 1.43209505e+00, -5.78843296e-01, -3.66053879e-01],\n",
              "         [ 1.28983891e+00,  1.46318388e+00,  3.70568961e-01],\n",
              "         [ 5.07189989e-01,  1.17345369e+00, -1.17389989e+00],\n",
              "         ...,\n",
              "         [-1.01769853e+00, -1.91461515e+00, -3.12233388e-01],\n",
              "         [-1.49731266e+00, -1.07522392e+00, -1.10670829e+00],\n",
              "         [ 1.12240575e-01,  3.23153138e-01, -9.59781528e-01]],\n",
              "\n",
              "        [[-1.35504651e+00, -1.17648113e+00, -3.99530649e-01],\n",
              "         [-2.08420992e+00, -1.06119335e+00, -1.81732082e+00],\n",
              "         [ 2.16140652e+00, -1.00878753e-01, -2.55770758e-02],\n",
              "         ...,\n",
              "         [-4.04274523e-01, -1.27282572e+00,  5.75866044e-01],\n",
              "         [ 7.43096709e-01,  9.10562694e-01,  1.00143802e+00],\n",
              "         [-8.66966099e-02, -1.09531105e+00, -6.69030070e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.43014300e-01, -1.35098109e-02, -3.22903454e-01],\n",
              "         [-8.52823138e-01,  9.50612843e-01, -1.05394185e+00],\n",
              "         [-2.21011668e-01, -8.63013744e-01,  1.05244565e+00],\n",
              "         ...,\n",
              "         [-4.93951231e-01, -1.65642166e+00, -1.28688467e+00],\n",
              "         [ 2.18934923e-01,  9.45915699e-01, -4.07542735e-01],\n",
              "         [ 1.94882131e+00, -7.77700841e-01, -2.00122878e-01]],\n",
              "\n",
              "        [[-5.47967553e-02, -5.46596348e-01, -2.30614996e+00],\n",
              "         [ 8.46078515e-01,  6.95690095e-01,  6.56767666e-01],\n",
              "         [-2.45907173e-01,  7.17947960e-01, -5.78346737e-02],\n",
              "         ...,\n",
              "         [-7.07010746e-01, -4.35612321e-01, -1.12184119e+00],\n",
              "         [-1.91474819e+00,  3.50618094e-01,  1.21325696e+00],\n",
              "         [ 6.97672486e-01,  7.83810079e-01,  9.99754012e-01]],\n",
              "\n",
              "        [[-4.33989406e-01,  1.65746891e+00,  1.12178361e+00],\n",
              "         [-1.35984969e+00, -5.06404400e-01, -9.71680403e-01],\n",
              "         [ 2.06416264e-01, -5.52895308e-01, -2.13678050e+00],\n",
              "         ...,\n",
              "         [-6.28782928e-01,  1.14001262e+00, -4.95065510e-01],\n",
              "         [-2.32967064e-01,  7.18582034e-01,  7.93163955e-01],\n",
              "         [-7.63715863e-01,  6.88833237e-01,  9.33579147e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 2.81874478e-01, -2.10300732e+00, -1.66421509e+00],\n",
              "         [-3.10557127e-01,  4.90045594e-03, -5.76574266e-01],\n",
              "         [-2.62086451e-01,  4.77945209e-01, -2.28244007e-01],\n",
              "         ...,\n",
              "         [ 2.02324963e+00, -1.37567091e+00,  1.99186072e-01],\n",
              "         [-1.30328071e+00,  3.13517272e-01, -3.01323026e-01],\n",
              "         [-6.89406753e-01, -1.33035195e+00, -1.13187575e+00]],\n",
              "\n",
              "        [[ 8.05322289e-01,  8.56892765e-01, -1.36488557e+00],\n",
              "         [ 5.66866219e-01, -2.06711388e+00,  1.88268736e-01],\n",
              "         [-1.43608227e-01, -1.03252268e+00, -1.10530627e+00],\n",
              "         ...,\n",
              "         [ 1.25418317e+00, -1.62971830e+00,  7.80748487e-01],\n",
              "         [-2.03992772e+00,  1.97856333e-02,  7.78273821e-01],\n",
              "         [-7.83819795e-01, -2.59416819e-01,  8.22688401e-01]],\n",
              "\n",
              "        [[ 4.78260398e-01, -3.73081356e-01, -4.84535098e-01],\n",
              "         [-2.73760766e-01,  7.24192619e-01, -1.04123688e+00],\n",
              "         [ 2.88639575e-01,  8.94188523e-01, -1.42694533e+00],\n",
              "         ...,\n",
              "         [-7.03774929e-01, -1.71176970e+00,  1.11418307e+00],\n",
              "         [-4.73176502e-02,  3.29967022e-01, -2.28434354e-02],\n",
              "         [ 1.05863750e+00, -5.53700566e-01,  2.39426285e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-4.42917258e-01,  9.04736578e-01, -1.10596813e-01],\n",
              "         [-2.67283463e+00, -6.24142647e-01, -3.64273727e-01],\n",
              "         [-5.92475533e-02,  2.26363182e+00,  2.13148385e-01],\n",
              "         ...,\n",
              "         [-2.07086965e-01, -3.60121936e-01, -1.59272170e+00],\n",
              "         [ 3.52991968e-01, -5.10824680e-01, -1.07964516e+00],\n",
              "         [-6.40307307e-01,  1.10639524e+00, -1.55664623e+00]],\n",
              "\n",
              "        [[-8.71032298e-01,  1.49037659e+00,  1.58307344e-01],\n",
              "         [-1.06320012e+00, -3.72965753e-01,  2.32485723e+00],\n",
              "         [ 7.15844810e-01,  1.50187314e-03, -1.73038319e-01],\n",
              "         ...,\n",
              "         [ 4.82787967e-01, -5.55242956e-01,  6.39505744e-01],\n",
              "         [ 1.27841055e+00,  1.63375691e-01, -2.57477373e-01],\n",
              "         [-2.01457405e+00, -1.13114297e+00,  8.73403311e-01]],\n",
              "\n",
              "        [[ 3.73390794e-01,  2.69634604e-01,  2.41413653e-01],\n",
              "         [-5.14540493e-01, -1.23153353e+00, -8.12080622e-01],\n",
              "         [-9.14992273e-01, -8.29972327e-01,  1.03508186e+00],\n",
              "         ...,\n",
              "         [ 4.62556809e-01,  4.54468340e-01,  3.84352684e-01],\n",
              "         [-2.21953437e-01,  1.69866413e-01, -9.25756097e-01],\n",
              "         [ 1.52992058e+00,  4.98951703e-01,  2.00178432e+00]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Slice data from the last element. \n",
        "tensor_h[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MInqF7JCPWtg",
        "outputId": "31f6ff54-fd4d-4756-e2c1-23c950b89f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=\n",
              "array([[[[ 3.20220813e-02, -6.58975720e-01, -7.99338222e-01],\n",
              "         [ 3.72260094e-01,  1.79697621e+00, -1.47552681e+00],\n",
              "         [-2.41523072e-01,  2.96367288e-01,  3.29055876e-01],\n",
              "         ...,\n",
              "         [-1.00517547e+00,  1.60214972e+00, -7.39147067e-01],\n",
              "         [ 1.09214759e+00,  1.54992139e+00, -8.94285798e-01],\n",
              "         [-2.62214929e-01,  4.39197391e-01,  1.51579189e+00]],\n",
              "\n",
              "        [[ 3.50333333e-01,  5.38667105e-02,  1.54839277e+00],\n",
              "         [ 1.36311042e+00,  2.55138725e-01,  3.18276763e-01],\n",
              "         [-4.69795734e-01,  4.61675674e-01, -1.11373043e+00],\n",
              "         ...,\n",
              "         [-5.99532187e-01, -2.07754850e+00, -2.08721086e-01],\n",
              "         [-2.47637677e+00, -1.14004993e+00, -1.08890581e+00],\n",
              "         [ 4.57735509e-01,  1.18241596e+00, -4.71124709e-01]],\n",
              "\n",
              "        [[ 7.89984539e-02,  5.89958489e-01,  1.32196140e+00],\n",
              "         [ 1.19241923e-01, -1.11930239e+00,  5.66065051e-02],\n",
              "         [-1.41178894e+00,  5.60370870e-02, -6.00891531e-01],\n",
              "         ...,\n",
              "         [-7.30165839e-01, -4.46494609e-01, -1.56124151e+00],\n",
              "         [ 1.12571466e+00, -7.74870515e-01, -7.58526802e-01],\n",
              "         [ 4.38942611e-01, -1.35078681e+00, -1.15244234e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.06279659e+00, -1.28163433e+00, -1.84500825e+00],\n",
              "         [ 1.43440366e+00,  5.97340345e-01, -1.43251646e+00],\n",
              "         [-1.13914371e-01, -2.33217978e+00,  1.22702944e+00],\n",
              "         ...,\n",
              "         [-2.17943668e-01,  1.29608023e+00,  4.87404138e-01],\n",
              "         [-6.49404228e-01,  8.44438553e-01,  1.67352214e-01],\n",
              "         [ 1.91914424e-01, -1.20439552e-01, -7.07876623e-01]],\n",
              "\n",
              "        [[-9.73102391e-01,  1.43720508e+00, -1.98246038e+00],\n",
              "         [-8.86574805e-01, -6.35249853e-01,  1.23170722e+00],\n",
              "         [-3.21114250e-02,  7.70276189e-02, -2.20390767e-01],\n",
              "         ...,\n",
              "         [-3.11490625e-01, -5.37272811e-01,  8.43696535e-01],\n",
              "         [-1.02907372e+00, -1.26317871e+00,  1.27718556e+00],\n",
              "         [-1.52875856e-01, -5.26754320e-01,  5.45374036e-01]],\n",
              "\n",
              "        [[ 1.52581322e+00,  2.61611462e-01, -9.16973948e-01],\n",
              "         [ 1.97658730e+00, -9.98274207e-01,  5.86047471e-01],\n",
              "         [ 1.20567167e+00, -5.40087521e-01,  1.13369338e-01],\n",
              "         ...,\n",
              "         [-8.09189379e-01,  1.12123764e+00,  8.81230712e-01],\n",
              "         [-7.93019593e-01, -1.50294993e-02,  1.02733262e-01],\n",
              "         [ 5.43214381e-01,  9.25297499e-01,  8.07737350e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 2.81874478e-01, -2.10300732e+00, -1.66421509e+00],\n",
              "         [-3.10557127e-01,  4.90045594e-03, -5.76574266e-01],\n",
              "         [-2.62086451e-01,  4.77945209e-01, -2.28244007e-01],\n",
              "         ...,\n",
              "         [ 2.02324963e+00, -1.37567091e+00,  1.99186072e-01],\n",
              "         [-1.30328071e+00,  3.13517272e-01, -3.01323026e-01],\n",
              "         [-6.89406753e-01, -1.33035195e+00, -1.13187575e+00]],\n",
              "\n",
              "        [[ 8.05322289e-01,  8.56892765e-01, -1.36488557e+00],\n",
              "         [ 5.66866219e-01, -2.06711388e+00,  1.88268736e-01],\n",
              "         [-1.43608227e-01, -1.03252268e+00, -1.10530627e+00],\n",
              "         ...,\n",
              "         [ 1.25418317e+00, -1.62971830e+00,  7.80748487e-01],\n",
              "         [-2.03992772e+00,  1.97856333e-02,  7.78273821e-01],\n",
              "         [-7.83819795e-01, -2.59416819e-01,  8.22688401e-01]],\n",
              "\n",
              "        [[ 4.78260398e-01, -3.73081356e-01, -4.84535098e-01],\n",
              "         [-2.73760766e-01,  7.24192619e-01, -1.04123688e+00],\n",
              "         [ 2.88639575e-01,  8.94188523e-01, -1.42694533e+00],\n",
              "         ...,\n",
              "         [-7.03774929e-01, -1.71176970e+00,  1.11418307e+00],\n",
              "         [-4.73176502e-02,  3.29967022e-01, -2.28434354e-02],\n",
              "         [ 1.05863750e+00, -5.53700566e-01,  2.39426285e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-4.42917258e-01,  9.04736578e-01, -1.10596813e-01],\n",
              "         [-2.67283463e+00, -6.24142647e-01, -3.64273727e-01],\n",
              "         [-5.92475533e-02,  2.26363182e+00,  2.13148385e-01],\n",
              "         ...,\n",
              "         [-2.07086965e-01, -3.60121936e-01, -1.59272170e+00],\n",
              "         [ 3.52991968e-01, -5.10824680e-01, -1.07964516e+00],\n",
              "         [-6.40307307e-01,  1.10639524e+00, -1.55664623e+00]],\n",
              "\n",
              "        [[-8.71032298e-01,  1.49037659e+00,  1.58307344e-01],\n",
              "         [-1.06320012e+00, -3.72965753e-01,  2.32485723e+00],\n",
              "         [ 7.15844810e-01,  1.50187314e-03, -1.73038319e-01],\n",
              "         ...,\n",
              "         [ 4.82787967e-01, -5.55242956e-01,  6.39505744e-01],\n",
              "         [ 1.27841055e+00,  1.63375691e-01, -2.57477373e-01],\n",
              "         [-2.01457405e+00, -1.13114297e+00,  8.73403311e-01]],\n",
              "\n",
              "        [[ 3.73390794e-01,  2.69634604e-01,  2.41413653e-01],\n",
              "         [-5.14540493e-01, -1.23153353e+00, -8.12080622e-01],\n",
              "         [-9.14992273e-01, -8.29972327e-01,  1.03508186e+00],\n",
              "         ...,\n",
              "         [ 4.62556809e-01,  4.54468340e-01,  3.84352684e-01],\n",
              "         [-2.21953437e-01,  1.69866413e-01, -9.25756097e-01],\n",
              "         [ 1.52992058e+00,  4.98951703e-01,  2.00178432e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 1.28478277e+00, -2.46135578e-01,  7.63266087e-01],\n",
              "         [ 8.40199888e-01,  9.68266785e-01, -1.93278158e+00],\n",
              "         [-2.09653950e+00,  8.09427738e-01,  2.53316551e-01],\n",
              "         ...,\n",
              "         [ 7.27030933e-01, -4.74542752e-02,  8.99164498e-01],\n",
              "         [-8.15167308e-01,  4.26037997e-01, -6.86205089e-01],\n",
              "         [-4.67402607e-01, -2.35188913e+00, -2.83307910e-01]],\n",
              "\n",
              "        [[ 1.17288983e+00,  2.87962437e-01, -2.30707693e+00],\n",
              "         [-9.54468310e-01,  1.18314445e+00, -3.71690601e-01],\n",
              "         [ 1.45311785e+00, -1.12493455e+00, -2.05835223e-01],\n",
              "         ...,\n",
              "         [-4.36204791e-01,  7.51799226e-01,  7.72282302e-01],\n",
              "         [ 1.52221513e+00,  1.45522368e+00, -2.42574573e+00],\n",
              "         [-8.43710303e-01, -1.30115700e+00, -2.13285074e-01]],\n",
              "\n",
              "        [[-1.56356764e+00,  1.09605205e+00,  7.79315650e-01],\n",
              "         [-1.45281017e+00,  1.00318074e+00,  1.51921701e+00],\n",
              "         [ 1.42164469e+00,  3.23041707e-01,  6.56866014e-01],\n",
              "         ...,\n",
              "         [ 5.77209651e-01,  4.46495414e-01,  1.57666278e+00],\n",
              "         [-2.78246105e-01, -4.36549395e-01,  5.06283343e-01],\n",
              "         [ 5.07108450e-01,  1.08285439e+00,  4.25233424e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.78322330e-01,  8.77250373e-01, -7.05790937e-01],\n",
              "         [-4.01810259e-01, -4.60318238e-01,  2.78439224e-01],\n",
              "         [ 1.44627213e+00, -1.52383819e-01, -1.74593019e+00],\n",
              "         ...,\n",
              "         [ 1.31823853e-01,  9.76027429e-01,  3.30149770e-01],\n",
              "         [-2.89563447e-01, -3.92848730e+00, -3.17607373e-01],\n",
              "         [-1.43979311e+00,  2.10246108e-02, -3.12485874e-01]],\n",
              "\n",
              "        [[ 7.32896268e-01,  2.05464196e+00,  4.33212437e-04],\n",
              "         [ 1.37381685e+00, -6.49697185e-01,  1.08988702e+00],\n",
              "         [-4.28532809e-01, -1.50749922e+00, -2.40121388e+00],\n",
              "         ...,\n",
              "         [-2.34527612e+00,  4.20351326e-01,  9.06257272e-01],\n",
              "         [ 2.94619463e-02, -3.18071425e-01,  7.21470952e-01],\n",
              "         [-6.40402734e-01,  1.61624873e+00, -1.21447873e+00]],\n",
              "\n",
              "        [[-1.60136342e+00, -4.40431774e-01,  7.21037328e-01],\n",
              "         [-5.87926712e-03,  2.34594393e+00,  2.28388891e-01],\n",
              "         [-1.71428645e+00,  1.72451407e-01, -4.64472890e-01],\n",
              "         ...,\n",
              "         [-1.75712121e+00, -7.48715997e-01, -6.81563854e-01],\n",
              "         [-4.45661731e-02,  3.16094249e-01,  7.54296547e-03],\n",
              "         [-1.42325044e-01, -1.05170894e+00,  5.19285917e-01]]],\n",
              "\n",
              "\n",
              "       [[[-8.80348861e-01,  2.71405280e-01,  9.06207204e-01],\n",
              "         [ 5.93119740e-01,  6.82946861e-01, -2.47171447e-01],\n",
              "         [-6.65472150e-01,  2.81757998e+00,  6.49745345e-01],\n",
              "         ...,\n",
              "         [ 8.71333539e-01,  8.99664104e-01, -8.29841554e-01],\n",
              "         [ 1.13124812e+00,  5.36805332e-01, -1.40769601e+00],\n",
              "         [-1.37473714e+00, -1.72108233e+00,  3.42596382e-01]],\n",
              "\n",
              "        [[ 1.43209505e+00, -5.78843296e-01, -3.66053879e-01],\n",
              "         [ 1.28983891e+00,  1.46318388e+00,  3.70568961e-01],\n",
              "         [ 5.07189989e-01,  1.17345369e+00, -1.17389989e+00],\n",
              "         ...,\n",
              "         [-1.01769853e+00, -1.91461515e+00, -3.12233388e-01],\n",
              "         [-1.49731266e+00, -1.07522392e+00, -1.10670829e+00],\n",
              "         [ 1.12240575e-01,  3.23153138e-01, -9.59781528e-01]],\n",
              "\n",
              "        [[-1.35504651e+00, -1.17648113e+00, -3.99530649e-01],\n",
              "         [-2.08420992e+00, -1.06119335e+00, -1.81732082e+00],\n",
              "         [ 2.16140652e+00, -1.00878753e-01, -2.55770758e-02],\n",
              "         ...,\n",
              "         [-4.04274523e-01, -1.27282572e+00,  5.75866044e-01],\n",
              "         [ 7.43096709e-01,  9.10562694e-01,  1.00143802e+00],\n",
              "         [-8.66966099e-02, -1.09531105e+00, -6.69030070e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.43014300e-01, -1.35098109e-02, -3.22903454e-01],\n",
              "         [-8.52823138e-01,  9.50612843e-01, -1.05394185e+00],\n",
              "         [-2.21011668e-01, -8.63013744e-01,  1.05244565e+00],\n",
              "         ...,\n",
              "         [-4.93951231e-01, -1.65642166e+00, -1.28688467e+00],\n",
              "         [ 2.18934923e-01,  9.45915699e-01, -4.07542735e-01],\n",
              "         [ 1.94882131e+00, -7.77700841e-01, -2.00122878e-01]],\n",
              "\n",
              "        [[-5.47967553e-02, -5.46596348e-01, -2.30614996e+00],\n",
              "         [ 8.46078515e-01,  6.95690095e-01,  6.56767666e-01],\n",
              "         [-2.45907173e-01,  7.17947960e-01, -5.78346737e-02],\n",
              "         ...,\n",
              "         [-7.07010746e-01, -4.35612321e-01, -1.12184119e+00],\n",
              "         [-1.91474819e+00,  3.50618094e-01,  1.21325696e+00],\n",
              "         [ 6.97672486e-01,  7.83810079e-01,  9.99754012e-01]],\n",
              "\n",
              "        [[-4.33989406e-01,  1.65746891e+00,  1.12178361e+00],\n",
              "         [-1.35984969e+00, -5.06404400e-01, -9.71680403e-01],\n",
              "         [ 2.06416264e-01, -5.52895308e-01, -2.13678050e+00],\n",
              "         ...,\n",
              "         [-6.28782928e-01,  1.14001262e+00, -4.95065510e-01],\n",
              "         [-2.32967064e-01,  7.18582034e-01,  7.93163955e-01],\n",
              "         [-7.63715863e-01,  6.88833237e-01,  9.33579147e-01]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.3.2 Indexing"
      ],
      "metadata": {
        "id": "m--FeTYqPaRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic format of an index is as follows: `a[d1][d2][d3]`. "
      ],
      "metadata": {
        "id": "L9LYK0XEPxJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain the pixel in the position [20,40] in the second channel of the first image. \n",
        "tensor_h[0][19][39][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJxwRjfJPdjR",
        "outputId": "c7a0b9b8-7867-463c-9c6f-453101d9c730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-1.0976491>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the indexes of data to be extracted are nonconsecutive, `tf.gather` and `tf.gather_nd` are commonly used for data extraction in TensorFlow."
      ],
      "metadata": {
        "id": "qc6ALaYjP36Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To extract data from a particular dimension:     \n",
        "`tf.gather(params, indices,axis=None)`:    \n",
        "-  params: input tensor.\n",
        "-  indices: index of the data to be extracted.\n",
        "-  axis: dimension of the data to be extracted."
      ],
      "metadata": {
        "id": "1f9bF27OTDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the first, second, and fourth images from tensor_h ([4,100,100,3]). \n",
        "indices = [0,1,3] \n",
        "tf.gather(tensor_h,axis=0,indices=indices,batch_dims=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc8EmLb3TPRR",
        "outputId": "2e3255e4-ced2-43ac-f98b-82146dae78a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 100, 100, 3), dtype=float32, numpy=\n",
              "array([[[[ 2.0084465 , -2.3842397 ,  0.56350225],\n",
              "         [-0.22519012, -1.467062  ,  1.2867384 ],\n",
              "         [ 0.22692962, -1.8108065 , -0.3790379 ],\n",
              "         ...,\n",
              "         [-0.2686914 ,  0.9871089 ,  0.89998364],\n",
              "         [ 0.15595573,  0.40947148, -0.38696405],\n",
              "         [-0.0596903 , -0.8417322 ,  0.27858144]],\n",
              "\n",
              "        [[ 0.74453855, -0.7166861 , -0.87763757],\n",
              "         [-0.22609983, -0.38828808,  2.002849  ],\n",
              "         [-0.3537504 ,  0.44429556,  0.03500603],\n",
              "         ...,\n",
              "         [-0.19678767, -2.9079275 , -0.16309987],\n",
              "         [ 0.35830724,  0.15009251,  1.0155056 ],\n",
              "         [ 0.94981146,  0.0205699 , -1.1123472 ]],\n",
              "\n",
              "        [[ 0.6640408 , -1.8556162 , -0.36464202],\n",
              "         [ 0.14545   ,  1.1587137 ,  0.14326619],\n",
              "         [ 2.929728  , -0.9377867 ,  0.09968437],\n",
              "         ...,\n",
              "         [-0.9501617 ,  0.57695997,  1.7569122 ],\n",
              "         [ 0.8567236 ,  1.501124  , -1.2900442 ],\n",
              "         [-0.31652054, -0.95529073, -2.7000732 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.34208766, -0.22550887,  0.27934602],\n",
              "         [-1.2576056 ,  1.2092503 , -0.8549812 ],\n",
              "         [ 1.0419973 , -2.3677397 , -0.8147056 ],\n",
              "         ...,\n",
              "         [ 0.36284995,  0.48161316,  0.06349012],\n",
              "         [ 0.98407686,  1.1757438 ,  0.7150653 ],\n",
              "         [-1.7535636 ,  0.08025788, -1.39991   ]],\n",
              "\n",
              "        [[-0.47392303,  1.5250245 , -0.2579051 ],\n",
              "         [ 0.58722043,  0.60294855,  0.71258974],\n",
              "         [-1.2147799 ,  0.8108134 ,  1.9464319 ],\n",
              "         ...,\n",
              "         [-0.64686996,  0.7635501 , -0.57517856],\n",
              "         [-1.4359707 , -2.218749  ,  0.26840273],\n",
              "         [ 1.8579803 ,  1.3958024 , -0.8683945 ]],\n",
              "\n",
              "        [[ 1.9146159 ,  1.4838451 ,  0.23851646],\n",
              "         [ 0.17559691, -1.5608926 , -0.3723852 ],\n",
              "         [-0.4916337 , -0.7309565 , -0.65572536],\n",
              "         ...,\n",
              "         [ 1.3431171 , -0.98677385,  2.8708825 ],\n",
              "         [-0.5245141 ,  1.4790332 ,  1.5955522 ],\n",
              "         [-0.34914663,  0.14998667,  0.7894867 ]]],\n",
              "\n",
              "\n",
              "       [[[ 1.0432037 , -0.48840052,  0.35273162],\n",
              "         [ 1.1988196 ,  1.1104352 ,  0.85888016],\n",
              "         [-0.31555405, -0.15311916, -0.12466754],\n",
              "         ...,\n",
              "         [-0.06438611,  1.5363586 , -0.83453506],\n",
              "         [-0.06220408,  0.2777116 ,  0.94769835],\n",
              "         [-1.1419035 , -1.2391819 , -1.2543893 ]],\n",
              "\n",
              "        [[-1.6416109 ,  1.9387633 ,  0.96000654],\n",
              "         [ 0.68512845,  0.68718934,  0.42341736],\n",
              "         [ 0.26607135, -1.7182292 , -0.29828382],\n",
              "         ...,\n",
              "         [ 1.3572624 , -0.56643504,  0.2824153 ],\n",
              "         [-1.3284883 ,  1.9471941 , -0.09517388],\n",
              "         [ 0.05150205,  0.51458174,  0.94950837]],\n",
              "\n",
              "        [[ 0.7065952 , -1.8301507 , -0.7118582 ],\n",
              "         [-0.22315462,  0.62866855,  1.6243789 ],\n",
              "         [ 0.6225952 ,  1.4782321 ,  0.335825  ],\n",
              "         ...,\n",
              "         [-0.65641886, -0.95866966, -0.7591829 ],\n",
              "         [-0.9693825 , -0.4719035 ,  0.72193813],\n",
              "         [-0.5302901 ,  0.03412354, -0.33729404]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.7390321 , -0.33594278, -0.67695314],\n",
              "         [-0.40670684, -1.2564341 , -1.7965581 ],\n",
              "         [ 1.5278707 , -0.37005004,  1.5284746 ],\n",
              "         ...,\n",
              "         [-0.6621884 ,  0.12386459,  0.3974331 ],\n",
              "         [ 0.05854509,  0.63397753,  0.9395775 ],\n",
              "         [-0.6220148 ,  0.03264763, -1.2529498 ]],\n",
              "\n",
              "        [[ 0.35406584,  1.2530392 ,  0.52303714],\n",
              "         [ 1.5706031 , -0.608344  ,  0.6900473 ],\n",
              "         [ 1.7523348 ,  1.332225  , -0.3206987 ],\n",
              "         ...,\n",
              "         [-0.64870656, -0.53315204,  1.186043  ],\n",
              "         [-1.3372248 , -0.5010705 ,  1.1483107 ],\n",
              "         [ 1.7170058 ,  0.13743286, -0.02136746]],\n",
              "\n",
              "        [[-0.4753468 , -0.37832704,  0.7299511 ],\n",
              "         [-1.0945381 , -0.6677035 ,  0.63502926],\n",
              "         [ 1.1866845 ,  1.2028897 ,  0.09318817],\n",
              "         ...,\n",
              "         [-0.58943826, -0.73284274,  0.2495812 ],\n",
              "         [-0.13029008,  3.2098706 , -2.3860319 ],\n",
              "         [ 1.68725   , -0.10220559, -2.8147857 ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.5529566 ,  0.1155658 , -0.7055408 ],\n",
              "         [ 0.14597651,  0.59485745,  1.1475233 ],\n",
              "         [ 0.00396098, -1.2810512 , -2.4855573 ],\n",
              "         ...,\n",
              "         [-0.02317613, -0.5189256 ,  0.6681831 ],\n",
              "         [ 0.45959675, -1.0759548 ,  1.001662  ],\n",
              "         [-0.38183203, -0.24307685, -0.24658088]],\n",
              "\n",
              "        [[-0.24429773,  2.2841766 ,  0.01515295],\n",
              "         [ 0.5087808 ,  2.9437878 , -0.89439964],\n",
              "         [ 1.1443661 , -0.7176968 , -0.12872544],\n",
              "         ...,\n",
              "         [-0.0196014 ,  1.5585237 ,  0.39820376],\n",
              "         [-0.589797  , -0.6184509 ,  0.18886915],\n",
              "         [ 1.7325804 , -0.94233114, -0.9480304 ]],\n",
              "\n",
              "        [[-0.295738  , -0.08840344, -0.64426595],\n",
              "         [-1.2294381 , -1.2469609 ,  0.33797494],\n",
              "         [ 0.24055915,  0.6985752 ,  1.5798458 ],\n",
              "         ...,\n",
              "         [ 0.94770896,  1.0074633 , -0.54956156],\n",
              "         [-1.3928368 ,  1.0942163 , -0.61577517],\n",
              "         [ 0.0564768 , -1.1104403 , -0.66195166]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.7699427 ,  2.2569525 , -0.8911283 ],\n",
              "         [ 0.6136568 ,  0.69250053,  1.1654781 ],\n",
              "         [-1.3299057 ,  1.1202494 ,  0.70071465],\n",
              "         ...,\n",
              "         [-0.02386985,  1.4902561 , -2.0537608 ],\n",
              "         [ 0.41126615,  0.72349864,  0.02325086],\n",
              "         [-0.7537716 ,  0.240345  ,  1.821623  ]],\n",
              "\n",
              "        [[-0.76029444,  0.6470043 , -1.3541856 ],\n",
              "         [ 0.49342433, -0.04118648,  0.16311525],\n",
              "         [-0.45101357, -0.27858582, -0.2824424 ],\n",
              "         ...,\n",
              "         [-0.61010236, -1.3228902 , -0.887558  ],\n",
              "         [-1.7119286 ,  0.31364593, -0.20386484],\n",
              "         [ 1.0634319 , -0.64403623,  0.45787665]],\n",
              "\n",
              "        [[ 0.04570175,  2.470797  , -0.04227356],\n",
              "         [ 0.04128888, -0.58452755, -0.9426827 ],\n",
              "         [-0.3971889 , -1.9025813 ,  2.4163272 ],\n",
              "         ...,\n",
              "         [-1.6370504 ,  0.7635741 ,  1.9217668 ],\n",
              "         [-1.6036321 , -1.4124241 ,  0.4839444 ],\n",
              "         [-1.2832875 , -0.24189085, -1.0559434 ]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.gather_nd` allows indexes to be performed on multiple dimensions: `tf.gather_nd(params,indices)`:   \n",
        "-   params: input tensor.\n",
        "-   indices: index of the data to be extracted, which is generally a multidimensional list."
      ],
      "metadata": {
        "id": "nGy5wL_DTTTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the pixel in [1,1] from the first dimension of the first image and the pixel in [2,2] from the first dimension of the second image in tensot_h ([4,100,100,3]). \n",
        "indices = [[0,1,1,0],[1,2,2,0]] \n",
        "tf.gather_nd(tensor_h,indices=indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiwTxKHeTmpD",
        "outputId": "8e1c2bf6-b862-4230-b51c-d220b831896d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.22609983,  0.6225952 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.4 Tensor Dimension Modification"
      ],
      "metadata": {
        "id": "6zdl4RzjTpsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.4.1 Viewing\n"
      ],
      "metadata": {
        "id": "fdsoYv7RUR1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "const_d_1 = tf.constant([[1, 2, 3, 4]],shape=[2,2], dtype=tf.float32) \n",
        "#Three common methods for viewing a dimension: \n",
        "print(const_d_1.shape) \n",
        "print(const_d_1.get_shape()) \n",
        "print(tf.shape(const_d_1))\n",
        "print(tf.shape(const_d_1))#The output is a tensor. The value of the tensor indicates the size of the tensor dimension to be viewed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-9_6gs7UMIA",
        "outputId": "8c8d1182-0658-4d3d-f9ce-8080f0a9270c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2)\n",
            "(2, 2)\n",
            "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
            "tf.Tensor([2 2], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As described above, `.shape` and `.get_shape()` return TensorShape objects, and `tf.shape(x)` returns Tensor objects."
      ],
      "metadata": {
        "id": "k8KSgVoTUZ9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.4.2 Reshaping"
      ],
      "metadata": {
        "id": "9D-3oCbEUd99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.reshape(tensor,shape,name=None)`:\n",
        "-   tensor: input tensor\n",
        "-   shape: dimension of the reshaped tensor"
      ],
      "metadata": {
        "id": "Xm7TYMUDU3yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshape_1 = tf.constant([[1,2,3],[4,5,6]]) \n",
        "print(reshape_1) \n",
        "tf.reshape(reshape_1, (3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUbAIo3uUeTI",
        "outputId": "c9f9488d-dc8e-4f57-9c90-a030285d3faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.4.3 Expanding"
      ],
      "metadata": {
        "id": "Fgyn4gJ7UemH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.expand_dims(input,axis,name=None)`:\n",
        "-   input: input tensor\n",
        "-   axis: adds a dimension after the axis dimension. When the number of dimensions of the input data is $D$, the axis must fall in the range of $[-(D + 1), D]$ (included). A negative value indicates adding a dimension in reverse order."
      ],
      "metadata": {
        "id": "OA-CQ2h8VFSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image. \n",
        "expand_sample_1 = tf.random.normal([100,100,3], seed=1) \n",
        "print(\"size of the original data:\",expand_sample_1.shape) \n",
        "print(\"add a dimension before the first dimension (axis=0): \",tf.expand_dims(expand_sample_1, axis=0).shape) \n",
        "print(\"add a dimension before the second dimension (axis=1): \",tf.expand_dims(expand_sample_1, axis=1).shape) \n",
        "print(\"add a dimension after the last dimension (axis=-1): \",tf.expand_dims(expand_sample_1, axis=-1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCpAmMOSVO2L",
        "outputId": "e9384753-9f01-4bc3-e380-e294cfcf9e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (100, 100, 3)\n",
            "add a dimension before the first dimension (axis=0):  (1, 100, 100, 3)\n",
            "add a dimension before the second dimension (axis=1):  (100, 1, 100, 3)\n",
            "add a dimension after the last dimension (axis=-1):  (100, 100, 3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.4.4 Squeezing"
      ],
      "metadata": {
        "id": "JXsxbZ1wVPCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.squeeze(input,axis=None,name=None)`:\n",
        "-   input: input tensor\n",
        "-   axis: If axis is set to 1, dimension 1 needs to be deleted."
      ],
      "metadata": {
        "id": "OIdOQuePVPNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image. \n",
        "squeeze_sample_1 = tf.random.normal([1,100,100,3]) \n",
        "print(\"size of the original data:\",squeeze_sample_1.shape) \n",
        "squeezed_sample_1 = tf.squeeze(expand_sample_1) \n",
        "print(\"data size after dimension squeezing:\",squeezed_sample_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHF_gac7VPea",
        "outputId": "2e7cc51d-1561-45f1-fb5a-add8ae6e7118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (1, 100, 100, 3)\n",
            "data size after dimension squeezing: (100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.4.5 Transposing"
      ],
      "metadata": {
        "id": "lv5hd0iPVPqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.transpose(a,perm=None,conjugate=False,name='transpose')`:\n",
        "-   a: input tensor\n",
        "-   perm: tensor size sequence, generally used to transpose high-dimensional arrays\n",
        "-   conjugate: indicates complex number transpose.\n",
        "-   name: tensor name"
      ],
      "metadata": {
        "id": "42G_K7yiVP3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The transposition problem of the low dimension is simple. The input needs to be called by transposing tensors. \n",
        "tf.transpose\n",
        "trans_sample_1 = tf.constant([1,2,3,4,5,6],shape=[2,3]) \n",
        "print(\"size of the original data:\",trans_sample_1.shape) \n",
        "transposed_sample_1 = tf.transpose(trans_sample_1) \n",
        "print(\"size of transposed data:\",transposed_sample_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0_G4sbbVQQK",
        "outputId": "9e7b287c-49be-4bf4-ce10-e6bcc048db2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (2, 3)\n",
            "size of transposed data: (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`perm` is required for high-dimensional data transposition, and indicates the dimension sequence of the input tensor.      \n",
        "The original dimension sequence of a three-dimensional tensor is `[0, 1, 2]` (`perm`), indicating the length, width, and height of high-dimensional data, respectively.       \n",
        "Data dimensions can be transposed by changing the sequence of values in perm. "
      ],
      "metadata": {
        "id": "d6E9S_GtVQg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate an $ x 100 x 200 x 3 tensor to represent four 100 x 200 three-channel color images. \n",
        "trans_sample_2 = tf.random.normal([4,100,200,3]) \n",
        "print(\"size of the original data:\",trans_sample_2.shape) \n",
        "#Exchange the length and width for the four images. The original perm value is [0,1,2,3], and the new perm value is [0,2,1,3]. \n",
        "transposed_sample_2 = tf.transpose(trans_sample_2,[0,2,1,3]) \n",
        "print(\"size of transposed data:\",transposed_sample_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqnqt_QxVQsB",
        "outputId": "b23b5a16-59ba-4282-91a2-59a4816f2402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (4, 100, 200, 3)\n",
            "size of transposed data: (4, 200, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.4.6 Broadcasting"
      ],
      "metadata": {
        "id": "HoM73dEQXCRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`broadcast_to` is used to broadcast data from a low dimension to a high dimension.      \n",
        "`tf.broadcast_to(input,shape,name=None)`:\n",
        "-   input: input tensor\n",
        "-   shape: size of the output tensor"
      ],
      "metadata": {
        "id": "LFivXJ04XPyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "broadcast_sample_1 = tf.constant([1,2,3,4,5,6]) \n",
        "print(\"original data:\",broadcast_sample_1.numpy()) \n",
        "broadcasted_sample_1 = tf.broadcast_to(broadcast_sample_1,shape=[4,6]) \n",
        "print(\"broadcasted data:\",broadcasted_sample_1.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ci2ZqcDXQPg",
        "outputId": "23288895-cecb-44f7-ab94-20d2d1710b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original data: [1 2 3 4 5 6]\n",
            "broadcasted data: [[1 2 3 4 5 6]\n",
            " [1 2 3 4 5 6]\n",
            " [1 2 3 4 5 6]\n",
            " [1 2 3 4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#During the operation, if two arrays have different shapes, TensorFlow automatically triggers the broadcast mechanism as NumPy does. \n",
        "a = tf.constant([[ 0, 0, 0], [10,10,10], [20,20,20], [30,30,30]]) \n",
        "b = tf.constant([1,2,3])\n",
        "print(a + b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owJgxbokXgf3",
        "outputId": "0672477a-e33f-4c25-b6f6-294d37963e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3]\n",
            " [11 12 13]\n",
            " [21 22 23]\n",
            " [31 32 33]], shape=(4, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.5 Arithmetic Operations on Tensors"
      ],
      "metadata": {
        "id": "u2ML9QW2XgqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.5.1 Arithmetic Operations"
      ],
      "metadata": {
        "id": "2Zu1ZqtiXg4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main arithmetic operations include addition (`tf.add`), subtraction (`tf.subtract`), multiplication (`tf.multiply`), division (`tf.divide`), logarithm (`tf.math.log`), and powers (`tf.pow`). The following describes only one addition example. "
      ],
      "metadata": {
        "id": "eqXkZsAwXhEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[3, 5], [4, 8]]) \n",
        "b = tf.constant([[1, 6], [2, 9]]) \n",
        "print(tf.add(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2agJVTfXhPo",
        "outputId": "010b0b35-36a9-4889-9491-fa1757029052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4 11]\n",
            " [ 6 17]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.5.2 Matrix Multiplication"
      ],
      "metadata": {
        "id": "r0TYaEBSXQci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication is implemented by calling `tf.matmul`."
      ],
      "metadata": {
        "id": "nQj8zyTAYmfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.matmul(a,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0EVRasqYgBD",
        "outputId": "8905bd5e-bf13-4cea-b3fd-05292ff7b307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[13, 63],\n",
              "       [20, 96]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.5.3 Tensor Statistics Collections"
      ],
      "metadata": {
        "id": "BP3zlUcLYsoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods for collecting tensor statistics include:"
      ],
      "metadata": {
        "id": "vZZqwIE0Y76I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-   `tf.reduce_min/max/mean()`: calculates the minimum, maximum, and average values.\n",
        "-   `tf.argmax()/tf.argmin()`: calculates the positions of the maximum and minimum values.\n",
        "-   `tf.equal()`: checks whether two tensors are equal by element.\n",
        "-   `tf.unique()`: removes duplicate elements from tensors.\n",
        "-   `tf.nn.in_top_k(prediction, target, K)`: calculates whether the predicted value is equal to the actual value, and returns a Boolean tensor."
      ],
      "metadata": {
        "id": "UA5TXE2gYyGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following describes how to use `tf.argmax()`: Return the position of the maximum value.    \n",
        "-   tf.argmax(input,axis)\n",
        "-   input: input tensor\n",
        "-   axis: maximum output value in the axis dimension"
      ],
      "metadata": {
        "id": "uppLBZcAYySC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "argmax_sample_1 = tf.constant([[1,3,2],[2,5,8],[7,5,9]]) \n",
        "print(\"input tensor:\",argmax_sample_1.numpy()) \n",
        "max_sample_1 = tf.argmax(argmax_sample_1, axis=0) \n",
        "max_sample_2 = tf.argmax(argmax_sample_1, axis=1) \n",
        "print(\"locate the maximum value by column:\",max_sample_1.numpy()) \n",
        "print(\"locate the maximum value by row:\",max_sample_2.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZypLTjxGYyjs",
        "outputId": "659361e4-ad97-4bd4-c839-3cf455fd23d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor: [[1 3 2]\n",
            " [2 5 8]\n",
            " [7 5 9]]\n",
            "locate the maximum value by column: [2 1 2]\n",
            "locate the maximum value by row: [1 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.6 Dimension-based Arithmetic Operations"
      ],
      "metadata": {
        "id": "Hde3zipRYywd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, a series of operations of `tf.reduce_*` reduce tensor dimensions. The series of operations can be performed on dimensional elements of a tensor, for example, calculating the mean value by row and calculating a product of all elements in the tensor. Common operations include `tf.reduce_sum` (addition), `tf.reduce_prod` (multiplication), `tf.reduce_min` (minimum), `tf.reduce_max` (maximum), `tf.reduce_mean` (mean value), `tf.reduce_all` (logical AND), `tf.reduce_any` (logical OR), and `tf.reduce_logsumexp` (log(sum(exp))).     \n",
        "\n",
        "The methods for using these operations are similar. The following describes how to use `tf.reduce_sum`. Calculate the sum of elements in each dimension of a tensor (`tf.reduce_sum(input_tensor, axis=None, keepdims=False,name=None)`):\n",
        "-   input_tensor: input tensor.\n",
        "-   axis: specifies axis to be calculated. If this parameter is not specified, the mean value of all elements is calculated.\n",
        "-   keepdims: specifies whether to keep dimensions. If this parameter is set to True, the output result retains the shape of the input tensor. If this parameter is set to False, dimensions of the output result decrease.\n",
        "-   name: operation name."
      ],
      "metadata": {
        "id": "oB3N3RMxYy88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_sample_1 = tf.constant([1,2,3,4,5,6],shape=[2,3]) \n",
        "print(\"original data\",reduce_sample_1.numpy()) \n",
        "print(\"calculate the sum of all elements in the tensor (axis=None): \",tf.reduce_sum(reduce_sample_1,axis=None).numpy())\n",
        "print(\"calculate the sum of elements in each column by column (axis=0): \",tf.reduce_sum(reduce_sample_1,axis=0).numpy())\n",
        "print(\"calculate the sum of elements in each column by row (axis=1): \",tf.reduce_sum(reduce_sample_1,axis=1).numpy())"
      ],
      "metadata": {
        "id": "o5bfsON3aQ6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab38014-5e43-4b7d-a7af-06e161147cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original data [[1 2 3]\n",
            " [4 5 6]]\n",
            "calculate the sum of all elements in the tensor (axis=None):  21\n",
            "calculate the sum of elements in each column by column (axis=0):  [5 7 9]\n",
            "calculate the sum of elements in each column by row (axis=1):  [ 6 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.7 Tensor Concatenation and String"
      ],
      "metadata": {
        "id": "656MYNt2am3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.7.1 Tensor Concatenation"
      ],
      "metadata": {
        "id": "lr6KnlSSanK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, tensor concatenation operations include:\n",
        "-   `tf.contact()`: concatenates vectors based on the specified dimension, while keeping other dimensions unchanged.\n",
        "-   `tf.stack()`: changes a group of R dimensional tensors to R+1 dimensional tensors, with the dimensions changed after the concatenation.\n",
        "`tf.concat(values, axis, name='concat')`:\n",
        "-   `tf.concat(values, axis, name='concat')`:\n",
        "   -   axis: dimension to concatenate\n",
        "   -   name: operation name"
      ],
      "metadata": {
        "id": "Jg9lhJ_tanUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concat_sample_1 = tf.random.normal([4,100,100,3]) \n",
        "concat_sample_2 = tf.random.normal([40,100,100,3]) \n",
        "print(\"sizes of original data: \",concat_sample_1.shape, concat_sample_2.shape) \n",
        "concated_sample_1 = tf.concat([concat_sample_1,concat_sample_2],axis=0) \n",
        "print(\"size of the concatenated data:\",concated_sample_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL7qM1PnbXHl",
        "outputId": "01153ce3-e604-495a-e87d-6cad5cb56548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sizes of original data:  (4, 100, 100, 3) (40, 100, 100, 3)\n",
            "size of the concatenated data: (44, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dimension is added to the original matrix. In the same way, the parameter axis determines the position of the dimension. `tf.stack(values, axis=0, name='stack')`:\n",
        "-   values: input tensors, a group of tensors with the same shape and data type.\n",
        "-   axis: dimension to concatenate.\n",
        "-   name: operation name."
      ],
      "metadata": {
        "id": "DqzQypP0bXT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stack_sample_1 = tf.random.normal([100,100,3]) \n",
        "stack_sample_2 = tf.random.normal([100,100,3]) \n",
        "print(\"sizes of original data: \",stack_sample_1.shape, stack_sample_2.shape) \n",
        "#Dimensions increase after the concatenation. If axis is set to 0, a dimension is added before the first dimension. \n",
        "stacked_sample_1 = tf.stack([stack_sample_1, stack_sample_2],axis=0) \n",
        "print(\"size of the concatenated data:\",stacked_sample_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPLPF0MnbXgw",
        "outputId": "d9d335f2-6769-4806-80ce-85544ac47335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sizes of original data:  (100, 100, 3) (100, 100, 3)\n",
            "size of the concatenated data: (2, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.7.2 Tensor Splitting"
      ],
      "metadata": {
        "id": "MRBBoDcRbXty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, tensor splitting operations include:\n",
        "-   `tf.unstack()`: splits a tensor by a specific dimension.\n",
        "-   `tf.split()`: splits a tensor into a specified number of sub tensors based on a specific dimension. `tf.split()` is more flexible than `tf.unstack()`. \n",
        "-   `tf.unstack(value,num=None,axis=0,name='unstack')`:\n",
        "    - value: input tensor\n",
        "    - num: indicates that a list containing num elements is output. The value of num must be the same as the number of elements in the specified dimension. This parameter can generally be ignored.\n",
        "    - axis: indicates the dimension based on which the tensor is split.\n",
        "    - name: operation name"
      ],
      "metadata": {
        "id": "LmHOoXrIanfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data based on the first dimension and output the split data in a list. \n",
        "tf.unstack(stacked_sample_1,axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAcf2zkganor",
        "outputId": "1eb32b80-22db-4796-e5c4-7283e1b0dea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
              " array([[[ 1.0795841e+00,  2.3944825e-01,  9.1100299e-01],\n",
              "         [ 1.4772649e+00,  1.2280364e-01,  7.2891462e-01],\n",
              "         [-7.6034099e-01,  1.9737576e-01,  6.0102546e-01],\n",
              "         ...,\n",
              "         [ 6.2063444e-01,  6.6213870e-01,  1.2835922e+00],\n",
              "         [ 1.4196913e+00,  1.8027763e-01, -1.8708650e+00],\n",
              "         [ 7.7581137e-02, -2.0267100e+00,  2.7890655e-01]],\n",
              " \n",
              "        [[-6.5171856e-01,  5.2171469e-01,  2.6435584e-01],\n",
              "         [ 7.7006048e-01,  8.1917804e-01, -9.6123838e-01],\n",
              "         [-1.7887808e+00,  1.7559530e-01,  3.6230925e-01],\n",
              "         ...,\n",
              "         [-1.1495495e+00,  7.4500996e-01, -1.4314164e+00],\n",
              "         [-2.7768591e-01,  1.0672805e+00,  2.6338193e-01],\n",
              "         [-2.1706166e+00, -5.1850730e-01,  7.6902115e-01]],\n",
              " \n",
              "        [[ 7.0715255e-01, -1.7762740e-01,  5.1457429e-01],\n",
              "         [-7.3259586e-01, -9.5110081e-02, -2.5062966e-01],\n",
              "         [ 5.5227917e-01, -1.9421399e-01,  4.5688581e-02],\n",
              "         ...,\n",
              "         [ 2.1367280e-01, -4.4464394e-02,  7.7009636e-01],\n",
              "         [-1.1205169e+00, -2.1452203e-03, -3.6989656e-01],\n",
              "         [-9.5284104e-01, -7.8235787e-01,  3.8545778e-01]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-7.2418541e-02,  5.0135839e-01, -6.8972367e-01],\n",
              "         [-8.1989157e-01,  2.2865518e-03,  5.2925271e-01],\n",
              "         [-1.1089072e+00,  1.4294212e+00, -1.7821226e-01],\n",
              "         ...,\n",
              "         [ 5.0533593e-01,  1.1558800e+00, -5.6723040e-01],\n",
              "         [-1.4084210e+00, -1.6841588e+00, -5.8205515e-01],\n",
              "         [ 1.5788053e+00, -1.3429219e+00,  1.9090616e+00]],\n",
              " \n",
              "        [[ 1.7944924e+00, -5.1007453e-02,  1.8142285e+00],\n",
              "         [-6.3521528e-01,  1.6063380e+00,  2.9534621e+00],\n",
              "         [ 1.6310120e-01, -2.0956771e-01, -1.4246234e+00],\n",
              "         ...,\n",
              "         [ 9.1500205e-01, -5.6752525e-02,  2.9040810e-01],\n",
              "         [-5.3849566e-01, -1.1704080e+00, -2.4901841e+00],\n",
              "         [ 7.4835724e-01,  1.2918824e-01, -2.9699004e-01]],\n",
              " \n",
              "        [[ 1.0103067e+00,  6.4405137e-01, -3.6374888e-01],\n",
              "         [ 4.7494274e-01, -4.3534362e-01,  2.9205847e-01],\n",
              "         [-1.7524780e+00,  3.8774133e-01,  8.5329600e-02],\n",
              "         ...,\n",
              "         [-1.5802894e+00,  1.4220675e+00,  4.7421020e-01],\n",
              "         [-1.2623464e-01, -7.9092944e-01, -2.4340813e-01],\n",
              "         [-1.2248312e+00,  3.4133530e-01, -1.0980188e+00]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
              " array([[[-0.2488476 , -0.14097168, -0.07109322],\n",
              "         [ 0.6878727 ,  0.70851666, -0.96330947],\n",
              "         [ 1.0630614 , -0.03546133,  1.4106777 ],\n",
              "         ...,\n",
              "         [ 1.9376273 , -0.5204994 , -0.17614855],\n",
              "         [ 1.5070497 , -1.6900007 ,  0.02786873],\n",
              "         [-1.0303638 ,  0.48098862,  1.3194747 ]],\n",
              " \n",
              "        [[ 0.2044201 ,  0.384626  , -2.0590332 ],\n",
              "         [ 1.5029778 , -0.5710751 , -1.3961755 ],\n",
              "         [-0.5533538 , -0.19052999, -2.8624723 ],\n",
              "         ...,\n",
              "         [-0.4591241 , -0.4865474 ,  0.5319412 ],\n",
              "         [ 1.6697074 , -0.4704181 ,  1.3105351 ],\n",
              "         [ 1.3268923 , -0.49739948,  1.7679304 ]],\n",
              " \n",
              "        [[-0.95253575, -0.6859718 ,  0.79136354],\n",
              "         [-0.00450075, -0.4553024 ,  0.2748785 ],\n",
              "         [ 1.4848446 , -0.458129  ,  0.61208594],\n",
              "         ...,\n",
              "         [ 0.2815031 , -0.06309883, -0.53496414],\n",
              "         [ 1.1868174 , -0.05560229,  1.2394732 ],\n",
              "         [-0.88285893,  0.62458605, -0.36733449]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 1.959493  , -0.74862033, -0.43427908],\n",
              "         [-1.1529435 , -1.1252419 , -0.41109973],\n",
              "         [-0.38820347, -0.01212122, -2.1722875 ],\n",
              "         ...,\n",
              "         [ 0.02905606, -0.8784157 , -0.4927618 ],\n",
              "         [ 0.24646698,  0.36075887, -0.04459204],\n",
              "         [-0.96699   ,  0.46797487,  0.25848112]],\n",
              " \n",
              "        [[ 0.20488322, -0.12984021, -2.561218  ],\n",
              "         [-1.4065443 , -1.2567228 , -0.45076478],\n",
              "         [-0.2602444 ,  1.3037039 , -0.8851842 ],\n",
              "         ...,\n",
              "         [-0.9027658 ,  0.14011501,  0.49445567],\n",
              "         [ 0.41153982, -0.05859981,  1.5456285 ],\n",
              "         [-1.8039019 ,  1.0998133 ,  0.66196924]],\n",
              " \n",
              "        [[ 0.54732096,  0.74332523, -0.7050011 ],\n",
              "         [ 1.1958106 , -1.0301832 ,  1.3410219 ],\n",
              "         [ 1.1847972 , -0.93806523, -0.08345239],\n",
              "         ...,\n",
              "         [ 0.21534124,  0.6475535 , -2.3643765 ],\n",
              "         [-0.01869496, -1.0512558 ,  1.6290947 ],\n",
              "         [-0.0237093 , -1.5795294 , -0.56708556]]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.split(value, num_or_size_splits, axis=0)`:\n",
        "-   value: input tensor\n",
        "-   num_or_size_splits: number of sub tensors\n",
        "-   axis: indicates the dimension based on which the tensor is split.   \n",
        "\n",
        "`tf.split()` splits a tensor in either of the following ways:  \n",
        "1.  If the value of `num_or_size_splits` is an integer, the tensor is evenly split into sub tensors in the specified dimension (`axis = D`). \n",
        "2.  If the value of `num_or_size_splits` is a vector, the tensor is split into sub tensors based on the element value of the vector in the specified dimension (`axis = D`)."
      ],
      "metadata": {
        "id": "12J0EUs2an06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "split_sample_1 = tf.random.normal([10,100,100,3]) \n",
        "print(\"size of the original data:\",split_sample_1.shape) \n",
        "splited_sample_1 = tf.split(split_sample_1, num_or_size_splits=5,axis=0) \n",
        "print(\"size of the split data when m_or_size_splits is set to 10: \",np.shape(splited_sample_1)) \n",
        "splited_sample_2 = tf.split(split_sample_1, num_or_size_splits=[3,5,2],axis=0) \n",
        "print(\"When num_or_size_splits=[3,5,2], the size of the split data is:\", np.shape(splited_sample_2[0]), np.shape(splited_sample_2[1]), np.shape(splited_sample_2[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1GpFaIaaoN2",
        "outputId": "226ad9a6-f065-4953-baf1-c43e78013bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (10, 100, 100, 3)\n",
            "size of the split data when m_or_size_splits is set to 10:  (5, 2, 100, 100, 3)\n",
            "When num_or_size_splits=[3,5,2], the size of the split data is: (3, 100, 100, 3) (5, 100, 100, 3) (2, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.8 Tensor Sorting"
      ],
      "metadata": {
        "id": "NZRgQva5aoZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, tensor sorting operations include:\n",
        "-   `tf.sort()`: sorts tensors in ascending or descending order and returns the sorted tensors.\n",
        "-   `tf.argsort()`: sorts tensors in ascending or descending order, and returns tensor indexes.\n",
        "-   `tf.nn.top_k()`: returns the first k maximum values. \n",
        "-   `tf.sort/argsort(input, direction, axis)`:\n",
        "    - input: input tensor\n",
        "    - direction: sorting order, which can be set to DESCENDING (descending order) or ASCENDING (ascending order). The default value is ASCENDING.\n",
        "    - axis: sorting by the dimension specified by axis. The default value of axis is 1, indicating the last dimension."
      ],
      "metadata": {
        "id": "vpIst2-eaokp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sort_sample_1 = tf.random.shuffle(tf.range(10)) \n",
        "print(\"input tensor:\",sort_sample_1.numpy()) \n",
        "sorted_sample_1 = tf.sort(sort_sample_1, direction=\"ASCENDING\") \n",
        "print(\"tensor sorted in ascending order:\",sorted_sample_1.numpy()) \n",
        "sorted_sample_2 = tf.argsort(sort_sample_1,direction=\"ASCENDING\") \n",
        "print(\"The indexes of elements of the tensors in ascending order:\",sorted_sample_2.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYmxZFh4aovm",
        "outputId": "24e7273b-c20f-4587-aa2c-610927d21d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor: [7 3 1 9 5 8 6 0 2 4]\n",
            "tensor sorted in ascending order: [0 1 2 3 4 5 6 7 8 9]\n",
            "The indexes of elements of the tensors in ascending order: [7 2 8 1 9 4 6 0 5 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.nn.top_k(input,K,sorted=TRUE)`:\n",
        "-  input: input tensor\n",
        "-  K: the first k values to be output and their indexes\n",
        "-  sorted: When sorted is set to TRUE, the tensor is sorted in ascending order. When sorted is set to FALSE, the tensor is sorted in descending order.    \n",
        "\n",
        "Return two tensors:\n",
        "-   values: k maximum values in each row.\n",
        "-   indices: positions of elements in the last dimension of the input tensor."
      ],
      "metadata": {
        "id": "UR9zwtvsao7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values, index = tf.nn.top_k(sort_sample_1,5) \n",
        "print(\"input tensor:\",sort_sample_1.numpy()) \n",
        "print(\"first five values in ascending order:\", values.numpy()) \n",
        "print(\"indexes of the first five values in ascending order:\", index.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOlcJ6phi7ia",
        "outputId": "7b0159ce-14ea-43a6-928c-205c105c2766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor: [7 3 1 9 5 8 6 0 2 4]\n",
            "first five values in ascending order: [9 8 7 6 5]\n",
            "indexes of the first five values in ascending order: [3 5 0 6 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Eager Execution Mode of TensorFlow 2"
      ],
      "metadata": {
        "id": "dsziElZ1i7t_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eager Execution mode:     \n",
        "The Eager Execution mode of TensorFlow is a type of imperative programming, which is the same as native Python. When you perform a particular operation, the system immediately returns a result.     \n",
        "     \n",
        "Graph mode:    \n",
        "TensorFlow 1.0 adopts the Graph mode to first build a computational graph, enable a Session, and then feed actual data to obtain a result. In Eager Execution mode, code debugging is easier, but the code execution efficiency is lower. The following implements simple multiplication by using TensorFlow to compare the differences between the Eager Execution mode and the Graph mode."
      ],
      "metadata": {
        "id": "FJdqbKFji749"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones((2, 2), dtype=tf.dtypes.float32) \n",
        "y = tf.constant([[1, 2], [3, 4]], dtype=tf.dtypes.float32) \n",
        "z = tf.matmul(x, y) \n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEIfrzkji8Eu",
        "outputId": "572fa991-9ec9-4e1f-d40c-4c5cfe4a2a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4. 6.]\n",
            " [4. 6.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the syntax of TensorFlow 1.x in TensorFlow 2. You can install the v1 compatibility package in TensorFlow 2.0 to inherit the TensorFlow 1.x code and disable the eager execution mode. \n",
        "import tensorflow.compat.v1 as tf \n",
        "tf.disable_eager_execution() \n",
        "#Create a graph and define it as a computational graph. \n",
        "a = tf.ones((2, 2), dtype=tf.dtypes.float32) \n",
        "b = tf.constant([[1, 2], [3, 4]], dtype=tf.dtypes.float32) \n",
        "c = tf.matmul(a, b) \n",
        "#Enable the drawing function, and perform the multiplication operation to obtain data. \n",
        "with tf.Session() as sess: \n",
        "  print(sess.run(c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfmJdtgCi8RR",
        "outputId": "061f7c7c-cdb5-4620-846d-5d298bbd4b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4. 6.]\n",
            " [4. 6.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the kernel to restore TensorFlow 2.0 and enable the eager execution mode. Another advantage of the Eager Execution mode lies in availability of native Python functions, for example, following condition statement:"
      ],
      "metadata": {
        "id": "VZWvWTjMi8dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "thre_1 = tf.random.uniform([], 0, 1)\n",
        "print(thre_1) \n",
        "x = tf.reshape(tf.range(0, 4), [2, 2]) \n",
        "print(x, x.shape)\n",
        "print(thre_1) \n",
        "if thre_1.numpy() > 0.5: \n",
        "  y = tf.matmul(x, x) \n",
        "else: \n",
        "  y = tf.add(x, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcuALYIoi8qB",
        "outputId": "a9acc480-863f-4ef5-fd90-14d68df515f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.97305, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0 1]\n",
            " [2 3]], shape=(2, 2), dtype=int32) (2, 2)\n",
            "tf.Tensor(0.97305, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jbYvGGws2mt",
        "outputId": "91842872-940a-4a67-b551-9d50e7e7f8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[0, 1],\n",
              "       [2, 3]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.matmul( x,x )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQSyyq12s4uG",
        "outputId": "0564ac0c-1dd0-4e19-b291-08749d9f424f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 2,  3],\n",
              "       [ 6, 11]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Owing to eager execution, this dynamic control flow can generate a NumPy value extractable by the Tensor, without using operators such as `tf.cond` and `tf.while` provided in Graph mode."
      ],
      "metadata": {
        "id": "R0RiIGL7i816"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.3 TensorFlow 2 AutoGraph"
      ],
      "metadata": {
        "id": "4q2F-QnnlKD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When being used to comment out a function, the decorator `tf.function` can be called like any other function. `tf.function` will be compiled into a graph, so that it can run more efficiently on a GPU or a TPU. In this case, the function becomes an operation in TensorFlow. The function can be directly called to output a return value. However, the function is executed in graph mode and intermediate variable values cannot be directly viewed."
      ],
      "metadata": {
        "id": "nXbjJYkvlKSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function \n",
        "def simple_nn_layer(w,x,b): \n",
        "  print(b) \n",
        "  return tf.nn.relu(tf.matmul(w, x)+b) \n",
        "\n",
        "w = tf.random.uniform((3, 3)) \n",
        "x = tf.random.uniform((3, 3)) \n",
        "b = tf.constant(0.5, dtype='float32') \n",
        "simple_nn_layer(w,x,b)"
      ],
      "metadata": {
        "id": "4GnsNf5DlKgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8f4214-1925-4aae-c1bb-599ff62fb098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"b:0\", shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0.99301225, 0.8322878 , 0.7498709 ],\n",
              "       [2.0350506 , 1.3445466 , 1.2469668 ],\n",
              "       [1.2125782 , 0.82355535, 1.1440252 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, x, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jc7l133tQ45",
        "outputId": "28e36609-1be2-4c51-cfeb-61518f931b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              " array([[0.24279857, 0.34399843, 0.09739316],\n",
              "        [0.90274036, 0.439322  , 0.55937123],\n",
              "        [0.11739755, 0.23000693, 0.5540775 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              " array([[0.89268386, 0.52160573, 0.00560164],\n",
              "        [0.558151  , 0.5255258 , 0.4461019 ],\n",
              "        [0.86522317, 0.2552812 , 0.97596645]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.5>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( simple_nn_layer(w,x,b) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miWXzC1KtWgR",
        "outputId": "54ae2d48-8179-4d72-c2b1-aa0106c2fe65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.99301225 0.8322878  0.7498709 ]\n",
            " [2.0350506  1.3445466  1.2469668 ]\n",
            " [1.2125782  0.82355535 1.1440252 ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the command output, the value of `b` in the function cannot be viewed directly, but the return value can be viewed using `.numpy()`. The following compares the performance of the graph mode and eager execution mode by performing the same operation (computation of one LSTM layer)."
      ],
      "metadata": {
        "id": "78j8X-JrlKtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the timeit module to measure the execution time of a small code segment. \n",
        "import timeit \n",
        "#Create a convolutional layer. \n",
        "CNN_cell = tf.keras.layers.Conv2D(filters=100,kernel_size=2,strides=(1,1)) \n",
        "#Use @tf.function to convert the operation into a graph. \n",
        "@tf.function \n",
        "def CNN_fn(image): \n",
        "  return CNN_cell(image) \n",
        "  \n",
        "image = tf.zeros([100, 200, 200, 3]) \n",
        "#Compare the execution time of the two modes. \n",
        "CNN_cell(image)\n",
        "CNN_fn(image) \n",
        "#Call timeit.timeit to measure the time required for executing the code 10 times. \n",
        "print(\"time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode:\", timeit.timeit(lambda: CNN_cell(image), number=10)) \n",
        "print(\"time required for performing the computation of one CNN layer in graph mode:\", timeit.timeit(lambda: CNN_fn(image), number=10))"
      ],
      "metadata": {
        "id": "TRyQ73RNlK5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e985926-f84b-48b0-b945-c10a30402517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode: 10.547819739000033\n",
            "time required for performing the computation of one CNN layer in graph mode: 7.478965428000038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison shows that the code execution efficiency in graph mode is much higher. Therefore, the `@tf.function` function can be used to improve the code execution efficiency."
      ],
      "metadata": {
        "id": "wTmdpFFLlLEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Common Modules of TensorFlow"
      ],
      "metadata": {
        "id": "j8-fja8sPntj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Introduction"
      ],
      "metadata": {
        "id": "moQnUY4qPnD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 About This Lab"
      ],
      "metadata": {
        "id": "2TsjAqsAlLPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section describes the common modules of TensorFlow 2, including:\n",
        "-   `tf.data`: performs operations on data sets, including reading data sets from the memory, reading CSV files, reading TFRecord files, and enhancing data.\n",
        "-   `tf.image`: processes images, including adjusting image brightness and saturation, converting image sizes, rotating images, and detecting edges.\n",
        "-   `tf.gfile`: implements operations on files, including reading, writing, and renaming files, and operating folders.\n",
        "-   `tf.keras`: a high-level API that is used to build and train deep learning models.\n",
        "-   `tf.distributions` and other modules.\n",
        "   \n",
        "This section focuses on the `tf.keras` module to lay a foundation for deep learning modeling."
      ],
      "metadata": {
        "id": "MuhTytfxlLas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Objectives"
      ],
      "metadata": {
        "id": "uSRuql7ClLml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon completion of this experiment, you will be able to:     \n",
        "Master the common deep learning modeling interfaces in `tf.keras`."
      ],
      "metadata": {
        "id": "w3XMKhpli9B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Procedure"
      ],
      "metadata": {
        "id": "JFNhhRWhi9NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Model Building"
      ],
      "metadata": {
        "id": "sHDH1R7zSvVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1.1 Building a Model by Stacking (`tf.keras.Sequential`)"
      ],
      "metadata": {
        "id": "k2YlQrvxSvga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most common way to build a model is to stack layers by using `tf.keras.Sequential`."
      ],
      "metadata": {
        "id": "gWhw098sSvrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1.2 Building a Functional Model"
      ],
      "metadata": {
        "id": "XeSyAoVeSv2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functional models are built mainly by using `tf.keras.Input` and `tf.keras.Model`, which are more complex than `tf.keras.Sequential` but have a good effect. Variables can be input at the same time or in different phases, and data can be output in different phases. Functional models are preferred if more than one model output is needed.    \n",
        "   \n",
        "Model stacking (.Sequential) vs Functional model (Model):    \n",
        "\n",
        "The `tf.keras.Sequential` model is a simple stack of layers and cannot represent any model. You can use the Keras functional model to build complex model topologies such as:\n",
        "- Multi-input models.\n",
        "- Multi-output models.\n",
        "- Models with shared layers.\n",
        "- Models with non-sequential data flows (for example, residual connections).      "
      ],
      "metadata": {
        "id": "siv0AEp5SwEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "#Use the output of the previous layer as the input of the next layer.\n",
        "x = tf.keras.Input(shape=(32,))\n",
        "h1 = layers.Dense(32, activation='relu')(x)\n",
        "h2 = layers.Dense(32, activation='relu')(h1)\n",
        "y = layers.Dense(10, activation='softmax')(h2)\n",
        "model_sample_2 = tf.keras.models.Model(x, y)\n",
        "#Print model information.\n",
        "model_sample_2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0M6TK4RSwQK",
        "outputId": "7f409add-62de-4eb1-9966-a58202ea2a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,442\n",
            "Trainable params: 2,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A number of weights in the first hidden layer is calculated as follows:"
      ],
      "metadata": {
        "id": "kPyXdSciv1gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "32 * 32 + 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aixt-XHNvO4x",
        "outputId": "7c64f7a5-9fc7-4767-cfa0-f67912d83750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1056"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1.3 Building a Network Layer (`tf.keras.Layers`)"
      ],
      "metadata": {
        "id": "diucI0w0Swby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `tf.keras.layers` module is used to configure neural network layers.     \n",
        "Common classes include:    \n",
        "- `tf.keras.layers.Dense`: builds a fully connected layer.\n",
        "- `tf.keras.layers.Conv2D`: builds a two-dimensional convolutional layer.\n",
        "- `tf.keras.layers.MaxPooling2D`/`AveragePooling2D`: builds a maximum/average pooling layer.\n",
        "- `tf.keras.layers.RNN`: builds a recurrent neural network layer.\n",
        "- `tf.keras.layers.LSTM`/`tf.keras.layers.LSTMCell`: builds an LSTM network layer/LSTM unit.\n",
        "-  `tf.keras.layers.GRU`/`tf.keras.layers.GRUCell`: builds a GRU unit/GRU network layer.\n",
        "-  `tf.keras.layers.Embedding`: converts a positive integer (subscript) into a vector of a fixed size, for example, `[[4],[20]]->[[0.25,0.1],[0.6,-0.2]]`. The embedding layer can only be used as the first model layer.\n",
        "- `tf.keras.layers.Dropout`: builds the dropout layer.\n",
        "- `tf.keras.layers.MaxPooling2D`/`AveragePooling2D`.\n",
        "- `tf.keras.layers.LSTM`/`tf.keras.layers.LSTMCell`.   \n",
        "    \n",
        "Main network configuration parameters in tf.keras.layers include:    \n",
        "- activation: sets the activation function for the layer. By default, the system applies no activation function.\n",
        "- kernel_initializer and bias_initializer: initialization schemes that create the layer's weights (kernel and bias). The default initializer is __Glorot_uniform__.\n",
        "- `kernel_regularizer` and `bias_regularizer`: regularization schemes that apply to the layer's weights (kernel and bias), such as L1 or L2 regularization.    \n",
        "By default, the system applies no regularization function."
      ],
      "metadata": {
        "id": "3kbIEaCMSwnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.2.1.3.1 `tf.keras.layers.Dense`"
      ],
      "metadata": {
        "id": "DB6Sl9AjVUE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main configuration parameters in `tf.keras.layers.Dense` include:    \n",
        "- units: number of neurons.\n",
        "- activation: sets the activation function.\n",
        "- use_bias: indicates whether to use bias terms. Bias terms are used by default.\n",
        "- kernel_initializer: initialization schemes that create the layer's weight (kernel).\n",
        "- bias_initializer: initialization schemes that create the layer's weight (bias).\n",
        "- kernel_regularizer: regularization schemes that apply to the layer's weight (kernel).\n",
        "- bias_regularizer: regularization schemes that apply to the layer's weight (bias).\n",
        "- activity_regularizer: regular item applied to the output, a Regularizer object.\n",
        "- kernel_constraint: a constraint applied to a weight.\n",
        "- bias_constraint: a constraint applied to a weight."
      ],
      "metadata": {
        "id": "FCEXk1AhVURk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a fully connected layer that contains 32 neurons. Set the activation function to sigmoid. \n",
        "#The activation parameter can be set to a function name string, for example, sigmoid or a function object, for example, tf.sigmoid. layers.Dense(32, activation='sigmoid') \n",
        "layers.Dense(32, activation=tf.sigmoid) \n",
        "#Set kernel_initializer \n",
        "layers.Dense(32, kernel_initializer=tf.keras.initializers.he_normal) \n",
        "#Set kernel_regularizer to L2 regularization \n",
        "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))"
      ],
      "metadata": {
        "id": "R1wjTAP2VUou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d097def2-2b0e-4281-f48a-70551d7149dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f65b15e1ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `tf.keras.layers.Conv2D`"
      ],
      "metadata": {
        "id": "xtdwocnZVU2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main configurable parameters in tf.keras.layers.Conv2D include:\n",
        "- filters: number of convolution kernels (output dimensions).\n",
        "- kernel_size: width and length of a convolution kernel.\n",
        "- strides: convolution step.\n",
        "- padding: zero padding policy.\n",
        "- When padding is set to valid, only valid convolution is performed, that is, boundary data is not processed. When padding is set to same, the convolution result at the boundary is reserved, and consequently, the output shape is usually the same as the input shape.\n",
        "- activation: sets the activation function.\n",
        "- data_format: data format, set to channels_first or channels_last. For example, for a 128 x 128 RGB image, data is organized as (3, 128, 128) if the value is channels_first, and (128, 128, 3) if the value is channels_last. The default value of this parameter is the value set in ~/.keras/keras.json. If the value is not set, the value is channels_last.\n",
        "- Other parameters include use_bias. kernel_initializer, bias_initializer, kernel_regularizer,\n",
        "bias_regularizer, activity_regularizer, kernel_constraints, and bias_constraints."
      ],
      "metadata": {
        "id": "c6eq50UzVVBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers.Conv2D(64,[1,1],2,padding='same',activation=\"relu\")"
      ],
      "metadata": {
        "id": "M-lVkptaVVLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf34f74-66c8-4e57-dfdd-c4120fae6556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7f36c908cb50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `tf.keras.layers.MaxPooling2D/AveragePooling2D`"
      ],
      "metadata": {
        "id": "SfenFGnqVVWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main configurable parameters in `tf.keras.layers.MaxPooling2D/AveragePooling2D` include:\n",
        "- pool_size: size of the pooled kernel. For example, if the matrix (2, 2) is used, the picture becomes half of the original length in both dimensions. If this parameter is set to an integer, the integer is the values of all dimensions.\n",
        "- strides: step.\n",
        "- Other parameters include `padding` and `data_format`."
      ],
      "metadata": {
        "id": "VRipmf1rVVmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `tf.keras.layers.LSTM/tf.keras.layers.LSTMCell`"
      ],
      "metadata": {
        "id": "uvsO1zibVVvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main configuration parameters in `tf.keras.layers.LSTM/tf.keras.layers.LSTMCell` include:\n",
        "- units: output dimension\n",
        "- input_shape (timestep and input_dim): timestep can be set to None, and input_dim indicates the input data dimension.\n",
        "- activation: sets the activation function.\n",
        "- recurrent_activation: activation function to use for the recurrent step.\n",
        "- return_sequences: If the value is True, the system returns the full sequence. If the value is False, the system returns the output of the last cell in the output sequence.\n",
        "- return_state: Boolean value, indicates whether to return the last state in addition to the output.\n",
        "- dropout: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the inputs.\n",
        "- recurrent_dropout: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the recurrent state."
      ],
      "metadata": {
        "id": "s0bTCp8YF6d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "inputs = tf.keras.Input(shape=(3, 1))\n",
        "lstm = layers.LSTM(1, return_sequences=True)(inputs)\n",
        "model_lstm_1 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
        "inputs = tf.keras.Input(shape=(3, 1))\n",
        "lstm = layers.LSTM(1, return_sequences=False)(inputs)\n",
        "model_lstm_2 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
        "#Sequences t1, t2, and t3\n",
        "data = np.array([[[0.1],\n",
        " [0.2],\n",
        " [0.3]]])\n",
        "print(data)\n",
        "print(\"output when return_sequences is set to True\",model_lstm_1.predict(data))\n",
        "print(\"output when return_sequences is set to False\",model_lstm_2.predict(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnDqIOxBGIpj",
        "outputId": "f0cb3b57-b44d-49e6-f657-1b1c7015f5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.1]\n",
            "  [0.2]\n",
            "  [0.3]]]\n",
            "output when return_sequences is set to True [[[0.00471112]\n",
            "  [0.01394265]\n",
            "  [0.02772297]]]\n",
            "output when return_sequences is set to False [[0.03427565]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMcell is the implementation unit of the LSTM layer.\n",
        "- LSTM is an LSTM network layer.\n",
        "- LSTMcell is a single-step computing unit, that is, an LSTM UNIT."
      ],
      "metadata": {
        "id": "ArZOZKFaGLMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.LSTM(16, return_sequences=True)\n",
        "#LSTMCell\n",
        "x = tf.keras.Input((None, 3))\n",
        "y = layers.RNN(layers.LSTMCell(16))(x)\n",
        "model_lstm_3= tf.keras.Model(x, y)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "TCS9ddNFGMlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training dan Evaluation"
      ],
      "metadata": {
        "id": "tWgdgi-qGMwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2.1 Compiling"
      ],
      "metadata": {
        "id": "weVB1mVbGM6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a model is built, you can call compile to configure the learning process of the model:\n",
        "- `compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None)`\n",
        "- `optimizer`: optimizer\n",
        "- `loss`: loss function, cross entropy for binary tasks and MSE for regression tasks\n",
        "- `metrics`: model evaluation criteria during training and testing For example, metrics can be set to `['accuracy']`. To specify multiple evaluation criteria, set a dictionary, for example, set metrics to `{'output_a':'accuracy'}`.\n",
        "- `loss_weights`: If the model has multiple task outputs, you need to specify a weight for each output when optimizing the global loss."
      ],
      "metadata": {
        "id": "2fyUAsY2Govz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine the optimizer (optimizer), loss function (loss), and model evaluation method (metrics).\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "#  loss=tf.keras.losses.categorical_crossentropy,\n",
        "#  metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        " loss=tf.keras.losses.categorical_crossentropy,\n",
        " metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "q_92VrumG9AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2.2 Training"
      ],
      "metadata": {
        "id": "WN-T24dAG_mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
        "validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,\n",
        "sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)`:\n",
        "- `x`: Input training data\n",
        "- `y`: Target (labeled) data\n",
        "- `batch_size`: Number of samples for each gradient update The default value is 32.\n",
        "- `epochs`: number of iteration rounds of the training model\n",
        "- `verbose`: log display mode, set to 0, 1, or 2. 0 = Not displayed, 1 = Progress bar, 2 = One line is displayed for each round.\n",
        "- `callbacks`: callback function used during training\n",
        "- `validation_split`: fraction of the training data to be used as validation data\n",
        "- `validation_data`: validation set. This parameter will overwrite validation_split.\n",
        "- `shuffle`: indicates whether to shuffle data before each round of iteration. This parameter is invalid when steps_per_epoch is not None.\n",
        "- `initial_epoch`: epoch at which to start training (useful for resuming a previous training weight)\n",
        "- `steps_per_epoch`: set to the dataset size or batch_size\n",
        "- `validation_steps`: This parameter is valid only when steps_per_epoch is specified. Total number of steps (batches of samples) to validate before stopping."
      ],
      "metadata": {
        "id": "e4crgkiMHCzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_x = np.random.random((1000, 36))\n",
        "train_y = np.random.random((1000, 10))\n",
        "val_x = np.random.random((200, 36))\n",
        "val_y = np.random.random((200, 10))\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
        " validation_data=(val_x, val_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xB7iCOgHk8h",
        "outputId": "cc35b9d4-3d2b-46a7-ca49-35c316df8c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 12.1368 - accuracy: 0.0880 - val_loss: 12.0538 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.1370 - accuracy: 0.0880 - val_loss: 12.0540 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1366 - accuracy: 0.0880 - val_loss: 12.0532 - val_accuracy: 0.1000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1361 - accuracy: 0.0880 - val_loss: 12.0528 - val_accuracy: 0.1000\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.1361 - accuracy: 0.0890 - val_loss: 12.0532 - val_accuracy: 0.1000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1365 - accuracy: 0.0890 - val_loss: 12.0535 - val_accuracy: 0.1000\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.1364 - accuracy: 0.0870 - val_loss: 12.0532 - val_accuracy: 0.1000\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1357 - accuracy: 0.0870 - val_loss: 12.0523 - val_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1354 - accuracy: 0.0880 - val_loss: 12.0521 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1351 - accuracy: 0.0880 - val_loss: 12.0520 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36c8ee7c90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use `tf.data` to build training input pipelines for large datasets."
      ],
      "metadata": {
        "id": "IEHCp-o5HlIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "val_dataset = val_dataset.repeat()\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
        " validation_data=val_dataset, validation_steps=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFkmAIeoHlSR",
        "outputId": "9422838a-128e-4725-f271-ffb9f74dc522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 12.1370 - accuracy: 0.0906 - val_loss: 12.2608 - val_accuracy: 0.0625\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1146 - accuracy: 0.0855 - val_loss: 12.2620 - val_accuracy: 0.0625\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1459 - accuracy: 0.0887 - val_loss: 12.2629 - val_accuracy: 0.0625\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1314 - accuracy: 0.0865 - val_loss: 12.2630 - val_accuracy: 0.0625\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1567 - accuracy: 0.0876 - val_loss: 12.2629 - val_accuracy: 0.0625\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1161 - accuracy: 0.0855 - val_loss: 12.2634 - val_accuracy: 0.0625\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1355 - accuracy: 0.0844 - val_loss: 12.2634 - val_accuracy: 0.0625\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1391 - accuracy: 0.0823 - val_loss: 12.2633 - val_accuracy: 0.0625\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1496 - accuracy: 0.0855 - val_loss: 12.2636 - val_accuracy: 0.0625\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12.1300 - accuracy: 0.0876 - val_loss: 12.2635 - val_accuracy: 0.0625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36c8f19350>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2.3 Evaluation and Prediction"
      ],
      "metadata": {
        "id": "HMUbIAg5Hl0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation and prediction functions: `tf.keras.Model.evaluate` and `tf.keras.Model.predict`."
      ],
      "metadata": {
        "id": "SjgZQyzKU1N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "test_x = np.random.random((1000, 36))\n",
        "test_y = np.random.random((1000, 10))\n",
        "model.evaluate(test_x, test_y, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CeZ0DpZVSgE",
        "outputId": "3c6a9112-97cc-422f-cf58-8969e9d275aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step - loss: 12.1756 - accuracy: 0.0960\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12.175633430480957, 0.09600000083446503]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model prediction\n",
        "pre_x = np.random.random((10, 36))\n",
        "result = model.predict(test_x,)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4GapCTzVUfx",
        "outputId": "5466ad62-44df-44e0-8762-875e5aaeb83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.17535621 0.04978991 0.09829897 ... 0.10383638 0.08252848 0.11058608]\n",
            " [0.11476804 0.07107837 0.09002225 ... 0.11701896 0.09721842 0.20127976]\n",
            " [0.16558827 0.02562624 0.09422886 ... 0.06423467 0.06907745 0.1387138 ]\n",
            " ...\n",
            " [0.09641905 0.03782939 0.04634167 ... 0.07893372 0.26409814 0.08445528]\n",
            " [0.1530797  0.04535627 0.08147073 ... 0.13212578 0.09456789 0.14203146]\n",
            " [0.1930565  0.03790967 0.08216567 ... 0.05633773 0.1485078  0.12483484]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZslFw18zSME",
        "outputId": "8f268e37-0508-41cd-caf3-c0c3affeea92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.17535621, 0.04978991, 0.09829897, 0.22407898, 0.05165542,\n",
              "       0.0383339 , 0.06553577, 0.10383638, 0.08252848, 0.11058608],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Model Saving and Restoration"
      ],
      "metadata": {
        "id": "NHF5iQ8gVV9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3.1 Saving and Restoring an Entire Model"
      ],
      "metadata": {
        "id": "DP5qkaStVWHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's prepare the google drive."
      ],
      "metadata": {
        "id": "RYLHOIwR9rWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "# Prepare the 'Drive'\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'Perkuliahan/HCIA-AI-Januari-2022/Codes/' # this is our working directory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IUwf5k28Bj5",
        "outputId": "ecf9ec47-7d16-4ea6-f1ea-753d80f431db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Save models.\n",
        "model.save( base_dir + 'model/the_save_model.h5'  ) \n",
        "#Import models.\n",
        "new_model = tf.keras.models.load_model( base_dir + 'model/the_save_model.h5' )\n",
        "new_prediction = new_model.predict(test_x)\n",
        "#np.testing.assert_allclose: determines whether the similarity between two objects exceeds the specified tolerance. If yes, the system displays an exception. :\n",
        "#atol: specified tolerance\n",
        "np.testing.assert_allclose(result, new_prediction, atol=1e-6) #Prediction results are the same."
      ],
      "metadata": {
        "id": "g9-OHuYXVWTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a model is saved, you can find the corresponding weight file in the corresponding folder."
      ],
      "metadata": {
        "id": "6BfJD6bCVWdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3.2 Saving and Loading Network Weights Only"
      ],
      "metadata": {
        "id": "oCS8HEAPVWm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the weight name is suffixed with `.h5` or `.keras`, save the weight as an HDF5 file, or otherwise, save the weight as a TensorFlow Checkpoint file by default."
      ],
      "metadata": {
        "id": "kPnTi77uAGyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(base_dir + 'model/model_weights')\n",
        "model.save_weights(base_dir + 'model/model_weights.h5')\n",
        "#Load the weights.\n",
        "model.load_weights(base_dir + 'model/model_weights')\n",
        "model.load_weights(base_dir + 'model/model_weights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_GhcyLdAJ5Z",
        "outputId": "a0439e46-6cfb-4a43-ba68-f471da841eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f36c23f85d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Image Recognition"
      ],
      "metadata": {
        "id": "5ixS8ha8Abyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Introduction"
      ],
      "metadata": {
        "id": "4dOI5hVCJd7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This experiment classifies images based on the `mnist_fashion` dataset."
      ],
      "metadata": {
        "id": "VHHiVfhzJeGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Procedure"
      ],
      "metadata": {
        "id": "7OE4_sktJeQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Importing the Dataset"
      ],
      "metadata": {
        "id": "epViFFknJebR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 Load the dataset.    \n",
        "Import the `tensorflow` library and then load the dataset."
      ],
      "metadata": {
        "id": "3KuUn3HDKKda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MqIoDFv0KTiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "fashion_mnist=tf.keras.datasets.fashion_mnist\n",
        "(train_X,train_y),(test_X,test_y)=fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkRrLgEKKRA4",
        "outputId": "d14222ea-085e-4611-b0f5-45f50ca6e6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the dataset is incorrectly stored, the `tensorflow` library will proactively load the dataset at a very low speed. In this case, consider accelerating the speed by using science-online tools. In addition, the dataset has been divided into the training set and test set. No additional division is required."
      ],
      "metadata": {
        "id": "mnsGbyPKKZg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 View the number of classes."
      ],
      "metadata": {
        "id": "DQARzg7CPgq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "len(Counter(train_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3oxs3dDPuCz",
        "outputId": "f616f5f6-4655-4519-c510-4525a8db7d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, `collections` in the standard library `python` is used to count the number of classes.     \n",
        "Ten classes are obtained and returned."
      ],
      "metadata": {
        "id": "uTZktyekPwVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 View images."
      ],
      "metadata": {
        "id": "T5WsP3wNP0h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_X[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PKgB3mxfQEqq",
        "outputId": "6139a7c0-2a06-416e-a136-5677eea2bf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f36c23fe710>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWQopwk22Wjn",
        "outputId": "e4f577cb-0adf-400a-8108-09c57e1afe1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Preprocessing Data"
      ],
      "metadata": {
        "id": "_ptiGgtzQJCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before writing neural networks correctly, preprocess the data so that the data complies with the input and output formats of the neural networks."
      ],
      "metadata": {
        "id": "RGnwAIz3RAFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 Perform one_hot_processing.    \n",
        "Perform one_hot processing on the __Target__ data (results) of the dataset."
      ],
      "metadata": {
        "id": "QlIgrWulRHW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_label=tf.keras.utils.to_categorical(train_y,num_classes=10)\n",
        "test_label=tf.keras.utils.to_categorical(test_y,num_classes=10)"
      ],
      "metadata": {
        "id": "AeeINmxURoqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter `num_classes=10` indicates that the dataset consists of `10` classes."
      ],
      "metadata": {
        "id": "QXxtAfjZRgq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 Stitch samples in batches and classify the samples into small batches.    \n",
        "    \n",
        "Map independent variables to dependent variables of the dataset, and then classify the samples into small batches to improve the gradient descent performance. In this example, 50 samples are classified to one group.    "
      ],
      "metadata": {
        "id": "TxKjdgitSrJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input=tf.data.Dataset.from_tensor_slices((train_X,train_label)).batch(50)\n",
        "test_input=tf.data.Dataset.from_tensor_slices((test_X,test_label)).batch(50)"
      ],
      "metadata": {
        "id": "WgcqYN3VS05w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BEGIN:MWE"
      ],
      "metadata": {
        "id": "QdJ3TB_VVEnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of `train_X` is `(60000, 28, 28)`.     \n"
      ],
      "metadata": {
        "id": "e3f9GkLiWvpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU4YR_9qVHi3",
        "outputId": "ce5d04c4-29d5-4078-8654-d4b3a3a15af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We divide the `train_X` and `train_label` into `50` batches accordingly.     \n",
        "We also divide the `test_X` and `test_label` into `50` batches as well.      "
      ],
      "metadata": {
        "id": "TrTwTDpMXa2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for element in train_input.as_numpy_iterator():\n",
        "  print(element[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAhM6G4rSpAn",
        "outputId": "0bf107c9-0ee6-4965-9356-cea4e845e631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n",
            "(50, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### END: MWE"
      ],
      "metadata": {
        "id": "4-i6F9vORG6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 Building a Neural Network"
      ],
      "metadata": {
        "id": "fBwpYO47RDqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 Define an input layer.**    \n",
        "Specify the number of neurons at the input layer. However, because the data is loaded in the matrix format at the beginning, the input layer is represented in the matrix format."
      ],
      "metadata": {
        "id": "gxUp4DhrZsJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data=tf.keras.Input([28,28])"
      ],
      "metadata": {
        "id": "tnLadiO_Z2Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 Flatten the data.**    \n",
        "Flatten the data to represent the data in the vector format."
      ],
      "metadata": {
        "id": "AgPxq5AOZv4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense=tf.keras.layers.Flatten()(input_data)"
      ],
      "metadata": {
        "id": "Vq9ATakkQQSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 Define a middle layer (hidden layer).**"
      ],
      "metadata": {
        "id": "ZS4oUEuiaJv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense=tf.keras.layers.Dense(100,activation='relu')(dense)\n",
        "dense=tf.keras.layers.Dense(100,activation='relu')(dense)\n",
        "dense=tf.keras.layers.Dense(100,activation='relu')(dense)\n",
        "dense=tf.keras.layers.Dense(100,activation='relu')(dense)"
      ],
      "metadata": {
        "id": "encV60GZaSJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, 100 neurons are defined for each layer, and the ReLU activation function is used."
      ],
      "metadata": {
        "id": "j6SdfqydaVug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 Define an output layer.    \n",
        "As ten classes are specified, ten neurons are required at the output layer, and the softmax activation is used."
      ],
      "metadata": {
        "id": "1zxRfdoeaYzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_data=tf.keras.layers.Dense(10,activation='softmax')(dense)"
      ],
      "metadata": {
        "id": "_LekrpWKahxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 Define the model sequence.     \n",
        "The overall model building process is complete so far. Afterwards, define the input and output sequences of the model."
      ],
      "metadata": {
        "id": "_CUlJ9uUalED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Model(inputs=input_data,outputs=output_data)"
      ],
      "metadata": {
        "id": "wlUJ2C06asMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 Define the loss function, optimizer, and training output information."
      ],
      "metadata": {
        "id": "hTd8-V2Jat9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(0.001),\n",
        "             loss=tf.losses.categorical_crossentropy,\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Mx_x_BgWb4Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the Adam optimizer, and set the learning rate to 0.001 and the loss function to the cross-entropy loss function.     \n",
        "Afterwards, output the accuracy rate of the current model after each round of training."
      ],
      "metadata": {
        "id": "8wmQgRBjb7GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 View the model."
      ],
      "metadata": {
        "id": "AdamNVX_cAvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHLtJpsNcGHr",
        "outputId": "bcbfb746-d81c-44c9-e502-d1b79640906a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,810\n",
            "Trainable params: 109,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the declared model by checking the number of parameters to be trained at each layer, the number of parameters to be trained on the entire network, and the number of neurons at each layer."
      ],
      "metadata": {
        "id": "MrEMlGmVcIXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8 Train the model.   \n",
        "Perform ten rounds of training."
      ],
      "metadata": {
        "id": "vnnR3aHQcxMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_input,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqDyCLZoc14Y",
        "outputId": "2c2461c3-5854-4ce9-83ad-26994275bc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1200/1200 [==============================] - 6s 4ms/step - loss: 0.9934 - accuracy: 0.7628\n",
            "Epoch 2/10\n",
            "1200/1200 [==============================] - 6s 5ms/step - loss: 0.4718 - accuracy: 0.8320\n",
            "Epoch 3/10\n",
            "1200/1200 [==============================] - 6s 5ms/step - loss: 0.4212 - accuracy: 0.8480\n",
            "Epoch 4/10\n",
            "1200/1200 [==============================] - 6s 5ms/step - loss: 0.3966 - accuracy: 0.8561\n",
            "Epoch 5/10\n",
            "1200/1200 [==============================] - 6s 5ms/step - loss: 0.3802 - accuracy: 0.8616\n",
            "Epoch 6/10\n",
            "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3596 - accuracy: 0.8696\n",
            "Epoch 7/10\n",
            "1200/1200 [==============================] - 6s 5ms/step - loss: 0.3491 - accuracy: 0.8736\n",
            "Epoch 8/10\n",
            "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3419 - accuracy: 0.8751\n",
            "Epoch 9/10\n",
            "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3299 - accuracy: 0.8796\n",
            "Epoch 10/10\n",
            "1200/1200 [==============================] - 5s 5ms/step - loss: 0.3237 - accuracy: 0.8811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36c3a45a90>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy rate of the model reaches `87%` after the training is complete."
      ],
      "metadata": {
        "id": "BjS5_6zRc3tE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9 Evaluate the model by using the test set.    \n",
        "Perform prediction evaluation by using the test set to determine whether the model is appropriate."
      ],
      "metadata": {
        "id": "RVcqNKQndKwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN0KhqtcdRBJ",
        "outputId": "65d6731a-b8e6-46da-d04e-842e3b403203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 1s 2ms/step - loss: 0.3783 - accuracy: 0.8652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3783268928527832, 0.8651999831199646]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the preceding figure, the accuracy rate is `85%`, indicating that the model is not overfitted, but the fitting degree is low. In this case, more neurons, a deeper network, and more datasets can be used to improve the model performance. A **convolutional neural network** (CNN) can be used alternatively. Due to the computer performance, convolution is performed."
      ],
      "metadata": {
        "id": "07RSk61ndUDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 Building a CNN"
      ],
      "metadata": {
        "id": "PwAG_Z2PdjiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During CNN building, data preprocessing takes a relatively long time because black-and-white images are used (there is only one color channel). However, the dataset is not defined. Therefore, you need to proactively add a dimension."
      ],
      "metadata": {
        "id": "4nsAu3BRdo00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=tf.expand_dims(train_X,-1)\n",
        "test_data=tf.expand_dims(test_X,-1)"
      ],
      "metadata": {
        "id": "nt783Jw5e_67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BEGIN: MWE"
      ],
      "metadata": {
        "id": "IfJSpQIOdtKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buNnMIWJe9In",
        "outputId": "2e9d4efd-5d99-4df3-db00-be2337340010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 28, 28, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### END: MWE"
      ],
      "metadata": {
        "id": "n4MvxsCIddwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, perform stitching and small-batch processing."
      ],
      "metadata": {
        "id": "xat_sUVFfLId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input=tf.data.Dataset.from_tensor_slices((train_data,train_label)).batch(50)\n",
        "test_input=tf.data.Dataset.from_tensor_slices((test_data,test_label)).batch(50)"
      ],
      "metadata": {
        "id": "NR0Ca1wyfa8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 Build an input layer.      \n",
        "In this example, single-channel gray images are used. However, convolutional input requires a multi-dimensional color channel for displaying the images.      \n",
        "     \n",
        "Therefore, a dimension needs to be added for output. If no dimension is added for the dataset, an error is reported because the input format of the dataset is different from that of the model."
      ],
      "metadata": {
        "id": "71FAf8izfdrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data=tf.keras.layers.Input([28,28,1])"
      ],
      "metadata": {
        "id": "hSlzRZ5Ifqzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 Build a convolutional layer."
      ],
      "metadata": {
        "id": "zlANuNP2fwoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv=tf.keras.layers.Conv2D(30,5,padding='SAME',activation='relu')(input_data)\n",
        "conv=tf.keras.layers.Conv2D(30,5,padding='SAME',activation='relu')(conv)"
      ],
      "metadata": {
        "id": "5E0z97Apf34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each of the 30 convolution kernels is used for 5 x 5 convolution, and the SAME operation is performed on the images. This operation expands the images before reprocessing to ensure that the image scale is not reduced due to convolution.      \n",
        "The ReLU activation function is used."
      ],
      "metadata": {
        "id": "MlpzL-oxf6Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 Build a pooling layer."
      ],
      "metadata": {
        "id": "CLEznjwugBcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv=tf.keras.layers.MaxPool2D(strides=[2,2])(conv)\n",
        "conv=tf.keras.layers.Conv2D(30,5,padding='SAME',activation='relu')(conv)"
      ],
      "metadata": {
        "id": "VubCxPQSgFvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A $2\\times2$ max pooling operation is performed, followed by a convolution operation."
      ],
      "metadata": {
        "id": "4TSJRfdhgP21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 Build a fully connected layer.    \n",
        "After the convolution is complete, flatten the neurons into vectors for subsequent classification, or continue to add a fully connected network layer."
      ],
      "metadata": {
        "id": "fmLZYh73gY0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense=tf.keras.layers.Flatten()(conv)\n",
        "output_data=tf.keras.layers.Dense(10,activation='relu')(dense)"
      ],
      "metadata": {
        "id": "P1h0xTn_ggXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistics show that the model accuracy rate will not increase on a CNN due to more fully connected layers or neurons. Therefore, no more fully connected layer is added to reduce the training time."
      ],
      "metadata": {
        "id": "PRVW7vQzgj3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 Determine the model and optimize the loss function."
      ],
      "metadata": {
        "id": "2nyd4__zgnKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Model(inputs=input_data,outputs=output_data)\n",
        "model.compile(optimizer=tf.optimizers.Adam(0.001),\n",
        "             loss=tf.losses.categorical_crossentropy,\n",
        "             metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVmNuB21g7Yc",
        "outputId": "6cf3d254-e0b4-403c-b58d-025c223a3b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 30)        780       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 30)        22530     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 30)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 30)        22530     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 5880)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                58810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,650\n",
            "Trainable params: 104,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the input and output positions of the model as before, and then specify the loss function and optimization method. Finally, view the model.    \n",
        "The preceding figure shows the input shape of each layer. Due to the SAME operation, no image scale is reduced during convolution."
      ],
      "metadata": {
        "id": "q6qZhg0mg9L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 Train and test the model."
      ],
      "metadata": {
        "id": "0DSDiqDVhdCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_input,epochs=1)\n",
        "model.evaluate(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HgyRJnRhgoX",
        "outputId": "392a66c4-65fd-4057-f836-1787e2af43b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 [==============================] - 389s 324ms/step - loss: nan - accuracy: 0.1013\n",
            "200/200 [==============================] - 16s 78ms/step - loss: nan - accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.10000000149011612]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only one round of training is performed as the CNN training is slow without being accelerated by a GPU."
      ],
      "metadata": {
        "id": "2sgCbLl2hifV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'Perkuliahan/HCIA-AI-Januari-2022/Codes/' # this is our working directory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5useqC20hwVi",
        "outputId": "0410ce1d-fdd6-450e-8b48-7163ab4ec3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 Save the model."
      ],
      "metadata": {
        "id": "BvdbgvSIh7oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(base_dir + \"model/model_cnn.h5\")"
      ],
      "metadata": {
        "id": "4XFy2LWElL8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8 Read the model."
      ],
      "metadata": {
        "id": "8XutLo6ylrG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelx = tf.keras.models.load_model( base_dir + \"model/model_cnn.h5\")"
      ],
      "metadata": {
        "id": "Cv_wU0z3lxww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelx.evaluate(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTq9zdF9l-mS",
        "outputId": "5f6fb9cc-197e-417a-993e-1925fde435cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 18s 89ms/step - loss: nan - accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.10000000149011612]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Recurrent Neural Network"
      ],
      "metadata": {
        "id": "vuX7Q8fYmCCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In probabilistic classification, the problem is to compute the probability of a label, conditioned on the text. Let's now consider the inverse problem: computing the probability of text itself. Specifically, we will consider models that assign probability to a sequence of\n",
        "word tokens, $\\Pr(w_1, w_2, \\ldots, w_M )$, with $w_m \\in \\mathcal{V}$ [(Eisenstein, 2019)](https://www.amazon.com/Introduction-Language-Processing-Adaptive-Computation/dp/0262042843).    \n",
        "    \n",
        "The set $\\mathcal{V}$ is a discrete vocabulary,   \n",
        "   \n",
        "$$\n",
        "  \\mathcal{V} = \\{ aardvark, abacus, \\ldots, zither \\}\n",
        "$$\n",
        "   \n",
        "Why would you want to compute the probability of a word sequence? In many applications, the goal is to produce word sequences as output:    \n",
        "*   In machine translation, we convert from text in a source language to\n",
        "text in a target language.\n",
        "*   In speech recognition, we convert from audio signal to text.\n",
        "*   In summarization, we convert from long texts into short texts.\n",
        "*   In dialogue systems, we convert from the users input (and perhaps an external knowledge base) into a text resrponse.\n",
        "   \n",
        "In many of the systems for performing these tasks, there is a subcomponent that computes the probability of the output text. The purpose of this component is to generate texts that are more **fluent**.    \n",
        "\n",
        "For example, suppose we want to translate a sentence from\n",
        "Spanish to English.\n",
        "     \n",
        "<center>\n",
        "El cafe negro me gusta mucho.\n",
        "</center>\n",
        "\n",
        "Here is a literal word-for-word translation (a **gloss**, a false and often willfully misleading interpretation (as of a text)):    \n",
        "   \n",
        "<center>\n",
        "The coffee black me pleases much.\n",
        "</center>   \n",
        "   \n",
        "A good language model of English will tell us that the probability of this translation is low, in comparison with more grammatical alternatives,\n",
        "\n",
        "$$\n",
        "  \\Pr(\\text{The coffee black me pleases much}) < \\Pr(\\text{I love dark coffee}) .\n",
        "$$\n",
        "\n",
        "This observation motivates a generative model (like Naive Bayes):\n",
        "* The English sentence $w^{(e)}$ is generated from a **language model**, $\\Pr_e({w}^{(e)} )$.\n",
        "* The Spanish sentence $w^{(s)}$ is then generated from a **translation model**, $\\Pr_{s \\mid e} (w^{(s)} | w^{(e)} )$\n",
        "    \n",
        "Given these two distributions, translation can be performed by Bayes' rule: \n",
        "\n",
        "$$\n",
        "  \\Pr_{e \\mid s}(w^{(e)} \\mid w )\n",
        "$$   \n"
      ],
      "metadata": {
        "id": "r-1KghHlP7XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7R5iKXWatOZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Model 1: One Word-In, One-Word-Out Sequences"
      ],
      "metadata": {
        "id": "1-uDxvJxhQgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "0uDgqlPwclHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tf.keras.preprocessing.text import Tokenizer\n",
        "# from tf.keras.utils import to_categorical\n",
        "# from tf.keras.utils.vis_utils import plot_model\n",
        "# from tf.keras.models import Sequential\n",
        "# from tf.keras.layers import Dense\n",
        "# from tf.keras.layers import LSTM\n",
        "# from tf.keras.layers import Embedding\n"
      ],
      "metadata": {
        "id": "8x5IDyFSae4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a sequence from the model\n",
        "def generate_seq(model, tokenizer, seed_text, n_words):\n",
        "  in_text, result = seed_text, seed_text\n",
        "  # generate a fixed number of words\n",
        "  for _ in range(n_words):\n",
        "   # encode the text as integer\n",
        "   encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "   encoded = array(encoded)\n",
        "   predict_x = model.predict(encoded)\n",
        "   yhat = np.argmax(predict_x, axis=1)\n",
        "   # map predicted word index to word\n",
        "   out_word = ''\n",
        "   for word, index in tokenizer.word_index.items():\n",
        "     if index == yhat:\n",
        "       out_word = word\n",
        "       break\n",
        "   # append to input\n",
        "   in_text, result = out_word, result + ' ' + out_word\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "jvI6WcLudQ93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "def define_model(vocab_size):\n",
        "\tmodel = tf.keras.models.Sequential()\n",
        "\tmodel.add(tf.keras.layers.Embedding(vocab_size, 10, input_length=1))\n",
        "\tmodel.add(tf.keras.layers.LSTM(50))\n",
        "\tmodel.add(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
        "\t# compile network\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# summarize defined model\n",
        "\tmodel.summary()\n",
        "\ttf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\treturn model\n"
      ],
      "metadata": {
        "id": "VBxf84bpdT4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source text\n",
        "data = \"\"\" Jack and Jill went up the hill\\n\n",
        "\t\tTo fetch a pail of water\\n\n",
        "\t\tJack fell down and broke his crown\\n\n",
        "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
        "# integer encode text\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded = tokenizer.texts_to_sequences([data])[0]\n",
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-N2qbCEdWxD",
        "outputId": "7bba9f9b-a0ae-432f-a1af-1170ce99c7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create word -> word sequences\n",
        "sequences = list()\n",
        "for i in range(1, len(encoded)):\n",
        "\tsequence = encoded[i-1:i+1]\n",
        "\tsequences.append(sequence)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "# split into X and y elements\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,0],sequences[:,1]\n",
        "# one hot encode outputs\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
        "# define model\n",
        "model = define_model(vocab_size)\n",
        "# fit network\n",
        "model.fit(X, y, epochs=500, verbose=2)\n",
        "# evaluate\n",
        "print(generate_seq(model, tokenizer, 'Jack', 6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxohsuhsdcct",
        "outputId": "013ed714-0449-48bc-8891-ccbefb30e5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 24\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 1, 10)             220       \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 50)                12200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 22)                1122      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,542\n",
            "Trainable params: 13,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "1/1 - 2s - loss: 3.0913 - accuracy: 0.0417 - 2s/epoch - 2s/step\n",
            "Epoch 2/500\n",
            "1/1 - 0s - loss: 3.0905 - accuracy: 0.1250 - 9ms/epoch - 9ms/step\n",
            "Epoch 3/500\n",
            "1/1 - 0s - loss: 3.0897 - accuracy: 0.0833 - 5ms/epoch - 5ms/step\n",
            "Epoch 4/500\n",
            "1/1 - 0s - loss: 3.0889 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 5/500\n",
            "1/1 - 0s - loss: 3.0881 - accuracy: 0.1250 - 8ms/epoch - 8ms/step\n",
            "Epoch 6/500\n",
            "1/1 - 0s - loss: 3.0873 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 7/500\n",
            "1/1 - 0s - loss: 3.0865 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 8/500\n",
            "1/1 - 0s - loss: 3.0857 - accuracy: 0.1250 - 7ms/epoch - 7ms/step\n",
            "Epoch 9/500\n",
            "1/1 - 0s - loss: 3.0849 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 10/500\n",
            "1/1 - 0s - loss: 3.0841 - accuracy: 0.1250 - 7ms/epoch - 7ms/step\n",
            "Epoch 11/500\n",
            "1/1 - 0s - loss: 3.0833 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 12/500\n",
            "1/1 - 0s - loss: 3.0824 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 13/500\n",
            "1/1 - 0s - loss: 3.0816 - accuracy: 0.1250 - 5ms/epoch - 5ms/step\n",
            "Epoch 14/500\n",
            "1/1 - 0s - loss: 3.0807 - accuracy: 0.1250 - 5ms/epoch - 5ms/step\n",
            "Epoch 15/500\n",
            "1/1 - 0s - loss: 3.0799 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 16/500\n",
            "1/1 - 0s - loss: 3.0790 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 17/500\n",
            "1/1 - 0s - loss: 3.0781 - accuracy: 0.1250 - 8ms/epoch - 8ms/step\n",
            "Epoch 18/500\n",
            "1/1 - 0s - loss: 3.0771 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 19/500\n",
            "1/1 - 0s - loss: 3.0762 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 20/500\n",
            "1/1 - 0s - loss: 3.0752 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 21/500\n",
            "1/1 - 0s - loss: 3.0743 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 22/500\n",
            "1/1 - 0s - loss: 3.0733 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 23/500\n",
            "1/1 - 0s - loss: 3.0722 - accuracy: 0.1250 - 9ms/epoch - 9ms/step\n",
            "Epoch 24/500\n",
            "1/1 - 0s - loss: 3.0712 - accuracy: 0.1250 - 5ms/epoch - 5ms/step\n",
            "Epoch 25/500\n",
            "1/1 - 0s - loss: 3.0701 - accuracy: 0.1250 - 12ms/epoch - 12ms/step\n",
            "Epoch 26/500\n",
            "1/1 - 0s - loss: 3.0690 - accuracy: 0.1250 - 4ms/epoch - 4ms/step\n",
            "Epoch 27/500\n",
            "1/1 - 0s - loss: 3.0679 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 28/500\n",
            "1/1 - 0s - loss: 3.0667 - accuracy: 0.1250 - 8ms/epoch - 8ms/step\n",
            "Epoch 29/500\n",
            "1/1 - 0s - loss: 3.0655 - accuracy: 0.1250 - 11ms/epoch - 11ms/step\n",
            "Epoch 30/500\n",
            "1/1 - 0s - loss: 3.0643 - accuracy: 0.1250 - 5ms/epoch - 5ms/step\n",
            "Epoch 31/500\n",
            "1/1 - 0s - loss: 3.0630 - accuracy: 0.1250 - 7ms/epoch - 7ms/step\n",
            "Epoch 32/500\n",
            "1/1 - 0s - loss: 3.0618 - accuracy: 0.1250 - 7ms/epoch - 7ms/step\n",
            "Epoch 33/500\n",
            "1/1 - 0s - loss: 3.0604 - accuracy: 0.1250 - 7ms/epoch - 7ms/step\n",
            "Epoch 34/500\n",
            "1/1 - 0s - loss: 3.0591 - accuracy: 0.1250 - 5ms/epoch - 5ms/step\n",
            "Epoch 35/500\n",
            "1/1 - 0s - loss: 3.0577 - accuracy: 0.1250 - 6ms/epoch - 6ms/step\n",
            "Epoch 36/500\n",
            "1/1 - 0s - loss: 3.0562 - accuracy: 0.1250 - 9ms/epoch - 9ms/step\n",
            "Epoch 37/500\n",
            "1/1 - 0s - loss: 3.0547 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 38/500\n",
            "1/1 - 0s - loss: 3.0532 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 39/500\n",
            "1/1 - 0s - loss: 3.0516 - accuracy: 0.2083 - 4ms/epoch - 4ms/step\n",
            "Epoch 40/500\n",
            "1/1 - 0s - loss: 3.0500 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 41/500\n",
            "1/1 - 0s - loss: 3.0483 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 42/500\n",
            "1/1 - 0s - loss: 3.0466 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 43/500\n",
            "1/1 - 0s - loss: 3.0449 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 44/500\n",
            "1/1 - 0s - loss: 3.0430 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 45/500\n",
            "1/1 - 0s - loss: 3.0412 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 46/500\n",
            "1/1 - 0s - loss: 3.0392 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 47/500\n",
            "1/1 - 0s - loss: 3.0372 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 48/500\n",
            "1/1 - 0s - loss: 3.0352 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 49/500\n",
            "1/1 - 0s - loss: 3.0331 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 50/500\n",
            "1/1 - 0s - loss: 3.0309 - accuracy: 0.2083 - 10ms/epoch - 10ms/step\n",
            "Epoch 51/500\n",
            "1/1 - 0s - loss: 3.0287 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/500\n",
            "1/1 - 0s - loss: 3.0264 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 53/500\n",
            "1/1 - 0s - loss: 3.0240 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 54/500\n",
            "1/1 - 0s - loss: 3.0216 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 55/500\n",
            "1/1 - 0s - loss: 3.0191 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 56/500\n",
            "1/1 - 0s - loss: 3.0165 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 57/500\n",
            "1/1 - 0s - loss: 3.0138 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 58/500\n",
            "1/1 - 0s - loss: 3.0111 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 59/500\n",
            "1/1 - 0s - loss: 3.0083 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 60/500\n",
            "1/1 - 0s - loss: 3.0054 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 61/500\n",
            "1/1 - 0s - loss: 3.0024 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 62/500\n",
            "1/1 - 0s - loss: 2.9993 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 63/500\n",
            "1/1 - 0s - loss: 2.9962 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 64/500\n",
            "1/1 - 0s - loss: 2.9929 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 65/500\n",
            "1/1 - 0s - loss: 2.9895 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 66/500\n",
            "1/1 - 0s - loss: 2.9861 - accuracy: 0.2083 - 13ms/epoch - 13ms/step\n",
            "Epoch 67/500\n",
            "1/1 - 0s - loss: 2.9825 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 68/500\n",
            "1/1 - 0s - loss: 2.9789 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 69/500\n",
            "1/1 - 0s - loss: 2.9751 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 70/500\n",
            "1/1 - 0s - loss: 2.9713 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 71/500\n",
            "1/1 - 0s - loss: 2.9673 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 72/500\n",
            "1/1 - 0s - loss: 2.9632 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 73/500\n",
            "1/1 - 0s - loss: 2.9590 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/500\n",
            "1/1 - 0s - loss: 2.9547 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 75/500\n",
            "1/1 - 0s - loss: 2.9502 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 76/500\n",
            "1/1 - 0s - loss: 2.9457 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 77/500\n",
            "1/1 - 0s - loss: 2.9410 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 78/500\n",
            "1/1 - 0s - loss: 2.9362 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 79/500\n",
            "1/1 - 0s - loss: 2.9312 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 80/500\n",
            "1/1 - 0s - loss: 2.9261 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 81/500\n",
            "1/1 - 0s - loss: 2.9209 - accuracy: 0.2083 - 10ms/epoch - 10ms/step\n",
            "Epoch 82/500\n",
            "1/1 - 0s - loss: 2.9156 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 83/500\n",
            "1/1 - 0s - loss: 2.9101 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 84/500\n",
            "1/1 - 0s - loss: 2.9044 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 85/500\n",
            "1/1 - 0s - loss: 2.8986 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/500\n",
            "1/1 - 0s - loss: 2.8927 - accuracy: 0.2083 - 11ms/epoch - 11ms/step\n",
            "Epoch 87/500\n",
            "1/1 - 0s - loss: 2.8866 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 88/500\n",
            "1/1 - 0s - loss: 2.8804 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 89/500\n",
            "1/1 - 0s - loss: 2.8740 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 90/500\n",
            "1/1 - 0s - loss: 2.8674 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 91/500\n",
            "1/1 - 0s - loss: 2.8607 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 92/500\n",
            "1/1 - 0s - loss: 2.8538 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 93/500\n",
            "1/1 - 0s - loss: 2.8467 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 94/500\n",
            "1/1 - 0s - loss: 2.8395 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 95/500\n",
            "1/1 - 0s - loss: 2.8321 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 96/500\n",
            "1/1 - 0s - loss: 2.8246 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 97/500\n",
            "1/1 - 0s - loss: 2.8169 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 98/500\n",
            "1/1 - 0s - loss: 2.8090 - accuracy: 0.2083 - 11ms/epoch - 11ms/step\n",
            "Epoch 99/500\n",
            "1/1 - 0s - loss: 2.8009 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 100/500\n",
            "1/1 - 0s - loss: 2.7927 - accuracy: 0.2083 - 10ms/epoch - 10ms/step\n",
            "Epoch 101/500\n",
            "1/1 - 0s - loss: 2.7842 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 102/500\n",
            "1/1 - 0s - loss: 2.7756 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 103/500\n",
            "1/1 - 0s - loss: 2.7669 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 104/500\n",
            "1/1 - 0s - loss: 2.7579 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 105/500\n",
            "1/1 - 0s - loss: 2.7488 - accuracy: 0.2083 - 10ms/epoch - 10ms/step\n",
            "Epoch 106/500\n",
            "1/1 - 0s - loss: 2.7395 - accuracy: 0.2083 - 4ms/epoch - 4ms/step\n",
            "Epoch 107/500\n",
            "1/1 - 0s - loss: 2.7300 - accuracy: 0.2083 - 6ms/epoch - 6ms/step\n",
            "Epoch 108/500\n",
            "1/1 - 0s - loss: 2.7203 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 109/500\n",
            "1/1 - 0s - loss: 2.7105 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 110/500\n",
            "1/1 - 0s - loss: 2.7005 - accuracy: 0.2083 - 7ms/epoch - 7ms/step\n",
            "Epoch 111/500\n",
            "1/1 - 0s - loss: 2.6903 - accuracy: 0.2083 - 11ms/epoch - 11ms/step\n",
            "Epoch 112/500\n",
            "1/1 - 0s - loss: 2.6799 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 113/500\n",
            "1/1 - 0s - loss: 2.6694 - accuracy: 0.2083 - 10ms/epoch - 10ms/step\n",
            "Epoch 114/500\n",
            "1/1 - 0s - loss: 2.6587 - accuracy: 0.2083 - 5ms/epoch - 5ms/step\n",
            "Epoch 115/500\n",
            "1/1 - 0s - loss: 2.6478 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 116/500\n",
            "1/1 - 0s - loss: 2.6367 - accuracy: 0.2083 - 10ms/epoch - 10ms/step\n",
            "Epoch 117/500\n",
            "1/1 - 0s - loss: 2.6255 - accuracy: 0.2083 - 9ms/epoch - 9ms/step\n",
            "Epoch 118/500\n",
            "1/1 - 0s - loss: 2.6142 - accuracy: 0.2083 - 8ms/epoch - 8ms/step\n",
            "Epoch 119/500\n",
            "1/1 - 0s - loss: 2.6026 - accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 120/500\n",
            "1/1 - 0s - loss: 2.5909 - accuracy: 0.2917 - 6ms/epoch - 6ms/step\n",
            "Epoch 121/500\n",
            "1/1 - 0s - loss: 2.5791 - accuracy: 0.2917 - 8ms/epoch - 8ms/step\n",
            "Epoch 122/500\n",
            "1/1 - 0s - loss: 2.5671 - accuracy: 0.2917 - 7ms/epoch - 7ms/step\n",
            "Epoch 123/500\n",
            "1/1 - 0s - loss: 2.5550 - accuracy: 0.2917 - 13ms/epoch - 13ms/step\n",
            "Epoch 124/500\n",
            "1/1 - 0s - loss: 2.5428 - accuracy: 0.2917 - 6ms/epoch - 6ms/step\n",
            "Epoch 125/500\n",
            "1/1 - 0s - loss: 2.5304 - accuracy: 0.2917 - 11ms/epoch - 11ms/step\n",
            "Epoch 126/500\n",
            "1/1 - 0s - loss: 2.5178 - accuracy: 0.2917 - 5ms/epoch - 5ms/step\n",
            "Epoch 127/500\n",
            "1/1 - 0s - loss: 2.5052 - accuracy: 0.2917 - 6ms/epoch - 6ms/step\n",
            "Epoch 128/500\n",
            "1/1 - 0s - loss: 2.4924 - accuracy: 0.2917 - 9ms/epoch - 9ms/step\n",
            "Epoch 129/500\n",
            "1/1 - 0s - loss: 2.4796 - accuracy: 0.2917 - 11ms/epoch - 11ms/step\n",
            "Epoch 130/500\n",
            "1/1 - 0s - loss: 2.4666 - accuracy: 0.3333 - 6ms/epoch - 6ms/step\n",
            "Epoch 131/500\n",
            "1/1 - 0s - loss: 2.4535 - accuracy: 0.3750 - 8ms/epoch - 8ms/step\n",
            "Epoch 132/500\n",
            "1/1 - 0s - loss: 2.4403 - accuracy: 0.3750 - 7ms/epoch - 7ms/step\n",
            "Epoch 133/500\n",
            "1/1 - 0s - loss: 2.4270 - accuracy: 0.3750 - 8ms/epoch - 8ms/step\n",
            "Epoch 134/500\n",
            "1/1 - 0s - loss: 2.4137 - accuracy: 0.3750 - 10ms/epoch - 10ms/step\n",
            "Epoch 135/500\n",
            "1/1 - 0s - loss: 2.4003 - accuracy: 0.3750 - 6ms/epoch - 6ms/step\n",
            "Epoch 136/500\n",
            "1/1 - 0s - loss: 2.3868 - accuracy: 0.3750 - 8ms/epoch - 8ms/step\n",
            "Epoch 137/500\n",
            "1/1 - 0s - loss: 2.3732 - accuracy: 0.3750 - 8ms/epoch - 8ms/step\n",
            "Epoch 138/500\n",
            "1/1 - 0s - loss: 2.3596 - accuracy: 0.3750 - 7ms/epoch - 7ms/step\n",
            "Epoch 139/500\n",
            "1/1 - 0s - loss: 2.3460 - accuracy: 0.4167 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/500\n",
            "1/1 - 0s - loss: 2.3323 - accuracy: 0.4167 - 11ms/epoch - 11ms/step\n",
            "Epoch 141/500\n",
            "1/1 - 0s - loss: 2.3185 - accuracy: 0.4167 - 9ms/epoch - 9ms/step\n",
            "Epoch 142/500\n",
            "1/1 - 0s - loss: 2.3047 - accuracy: 0.4167 - 6ms/epoch - 6ms/step\n",
            "Epoch 143/500\n",
            "1/1 - 0s - loss: 2.2909 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 144/500\n",
            "1/1 - 0s - loss: 2.2771 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 145/500\n",
            "1/1 - 0s - loss: 2.2633 - accuracy: 0.4167 - 4ms/epoch - 4ms/step\n",
            "Epoch 146/500\n",
            "1/1 - 0s - loss: 2.2495 - accuracy: 0.4167 - 9ms/epoch - 9ms/step\n",
            "Epoch 147/500\n",
            "1/1 - 0s - loss: 2.2356 - accuracy: 0.4167 - 6ms/epoch - 6ms/step\n",
            "Epoch 148/500\n",
            "1/1 - 0s - loss: 2.2218 - accuracy: 0.4167 - 5ms/epoch - 5ms/step\n",
            "Epoch 149/500\n",
            "1/1 - 0s - loss: 2.2079 - accuracy: 0.4167 - 8ms/epoch - 8ms/step\n",
            "Epoch 150/500\n",
            "1/1 - 0s - loss: 2.1941 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 151/500\n",
            "1/1 - 0s - loss: 2.1803 - accuracy: 0.4167 - 10ms/epoch - 10ms/step\n",
            "Epoch 152/500\n",
            "1/1 - 0s - loss: 2.1665 - accuracy: 0.4167 - 10ms/epoch - 10ms/step\n",
            "Epoch 153/500\n",
            "1/1 - 0s - loss: 2.1528 - accuracy: 0.4167 - 11ms/epoch - 11ms/step\n",
            "Epoch 154/500\n",
            "1/1 - 0s - loss: 2.1390 - accuracy: 0.4167 - 8ms/epoch - 8ms/step\n",
            "Epoch 155/500\n",
            "1/1 - 0s - loss: 2.1253 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 156/500\n",
            "1/1 - 0s - loss: 2.1117 - accuracy: 0.4167 - 11ms/epoch - 11ms/step\n",
            "Epoch 157/500\n",
            "1/1 - 0s - loss: 2.0980 - accuracy: 0.4167 - 5ms/epoch - 5ms/step\n",
            "Epoch 158/500\n",
            "1/1 - 0s - loss: 2.0844 - accuracy: 0.4167 - 9ms/epoch - 9ms/step\n",
            "Epoch 159/500\n",
            "1/1 - 0s - loss: 2.0709 - accuracy: 0.4167 - 6ms/epoch - 6ms/step\n",
            "Epoch 160/500\n",
            "1/1 - 0s - loss: 2.0574 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 161/500\n",
            "1/1 - 0s - loss: 2.0439 - accuracy: 0.4167 - 6ms/epoch - 6ms/step\n",
            "Epoch 162/500\n",
            "1/1 - 0s - loss: 2.0304 - accuracy: 0.4167 - 9ms/epoch - 9ms/step\n",
            "Epoch 163/500\n",
            "1/1 - 0s - loss: 2.0170 - accuracy: 0.4167 - 10ms/epoch - 10ms/step\n",
            "Epoch 164/500\n",
            "1/1 - 0s - loss: 2.0037 - accuracy: 0.4167 - 9ms/epoch - 9ms/step\n",
            "Epoch 165/500\n",
            "1/1 - 0s - loss: 1.9904 - accuracy: 0.4167 - 12ms/epoch - 12ms/step\n",
            "Epoch 166/500\n",
            "1/1 - 0s - loss: 1.9771 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 167/500\n",
            "1/1 - 0s - loss: 1.9639 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 168/500\n",
            "1/1 - 0s - loss: 1.9507 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 169/500\n",
            "1/1 - 0s - loss: 1.9376 - accuracy: 0.4167 - 7ms/epoch - 7ms/step\n",
            "Epoch 170/500\n",
            "1/1 - 0s - loss: 1.9245 - accuracy: 0.4583 - 8ms/epoch - 8ms/step\n",
            "Epoch 171/500\n",
            "1/1 - 0s - loss: 1.9114 - accuracy: 0.4583 - 6ms/epoch - 6ms/step\n",
            "Epoch 172/500\n",
            "1/1 - 0s - loss: 1.8984 - accuracy: 0.4583 - 6ms/epoch - 6ms/step\n",
            "Epoch 173/500\n",
            "1/1 - 0s - loss: 1.8854 - accuracy: 0.4583 - 8ms/epoch - 8ms/step\n",
            "Epoch 174/500\n",
            "1/1 - 0s - loss: 1.8724 - accuracy: 0.4583 - 5ms/epoch - 5ms/step\n",
            "Epoch 175/500\n",
            "1/1 - 0s - loss: 1.8595 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 176/500\n",
            "1/1 - 0s - loss: 1.8466 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 177/500\n",
            "1/1 - 0s - loss: 1.8338 - accuracy: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 178/500\n",
            "1/1 - 0s - loss: 1.8210 - accuracy: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 179/500\n",
            "1/1 - 0s - loss: 1.8082 - accuracy: 0.5417 - 7ms/epoch - 7ms/step\n",
            "Epoch 180/500\n",
            "1/1 - 0s - loss: 1.7954 - accuracy: 0.5417 - 8ms/epoch - 8ms/step\n",
            "Epoch 181/500\n",
            "1/1 - 0s - loss: 1.7827 - accuracy: 0.5417 - 6ms/epoch - 6ms/step\n",
            "Epoch 182/500\n",
            "1/1 - 0s - loss: 1.7700 - accuracy: 0.5417 - 6ms/epoch - 6ms/step\n",
            "Epoch 183/500\n",
            "1/1 - 0s - loss: 1.7573 - accuracy: 0.5417 - 6ms/epoch - 6ms/step\n",
            "Epoch 184/500\n",
            "1/1 - 0s - loss: 1.7447 - accuracy: 0.5833 - 14ms/epoch - 14ms/step\n",
            "Epoch 185/500\n",
            "1/1 - 0s - loss: 1.7321 - accuracy: 0.5833 - 4ms/epoch - 4ms/step\n",
            "Epoch 186/500\n",
            "1/1 - 0s - loss: 1.7195 - accuracy: 0.6250 - 5ms/epoch - 5ms/step\n",
            "Epoch 187/500\n",
            "1/1 - 0s - loss: 1.7069 - accuracy: 0.6250 - 5ms/epoch - 5ms/step\n",
            "Epoch 188/500\n",
            "1/1 - 0s - loss: 1.6944 - accuracy: 0.6250 - 6ms/epoch - 6ms/step\n",
            "Epoch 189/500\n",
            "1/1 - 0s - loss: 1.6818 - accuracy: 0.6250 - 7ms/epoch - 7ms/step\n",
            "Epoch 190/500\n",
            "1/1 - 0s - loss: 1.6693 - accuracy: 0.6250 - 8ms/epoch - 8ms/step\n",
            "Epoch 191/500\n",
            "1/1 - 0s - loss: 1.6568 - accuracy: 0.6250 - 6ms/epoch - 6ms/step\n",
            "Epoch 192/500\n",
            "1/1 - 0s - loss: 1.6444 - accuracy: 0.6250 - 6ms/epoch - 6ms/step\n",
            "Epoch 193/500\n",
            "1/1 - 0s - loss: 1.6319 - accuracy: 0.6250 - 9ms/epoch - 9ms/step\n",
            "Epoch 194/500\n",
            "1/1 - 0s - loss: 1.6195 - accuracy: 0.6250 - 7ms/epoch - 7ms/step\n",
            "Epoch 195/500\n",
            "1/1 - 0s - loss: 1.6071 - accuracy: 0.6250 - 8ms/epoch - 8ms/step\n",
            "Epoch 196/500\n",
            "1/1 - 0s - loss: 1.5947 - accuracy: 0.6250 - 10ms/epoch - 10ms/step\n",
            "Epoch 197/500\n",
            "1/1 - 0s - loss: 1.5824 - accuracy: 0.6250 - 11ms/epoch - 11ms/step\n",
            "Epoch 198/500\n",
            "1/1 - 0s - loss: 1.5701 - accuracy: 0.6250 - 10ms/epoch - 10ms/step\n",
            "Epoch 199/500\n",
            "1/1 - 0s - loss: 1.5578 - accuracy: 0.6250 - 4ms/epoch - 4ms/step\n",
            "Epoch 200/500\n",
            "1/1 - 0s - loss: 1.5455 - accuracy: 0.6250 - 10ms/epoch - 10ms/step\n",
            "Epoch 201/500\n",
            "1/1 - 0s - loss: 1.5332 - accuracy: 0.6667 - 7ms/epoch - 7ms/step\n",
            "Epoch 202/500\n",
            "1/1 - 0s - loss: 1.5210 - accuracy: 0.6667 - 6ms/epoch - 6ms/step\n",
            "Epoch 203/500\n",
            "1/1 - 0s - loss: 1.5087 - accuracy: 0.6667 - 10ms/epoch - 10ms/step\n",
            "Epoch 204/500\n",
            "1/1 - 0s - loss: 1.4966 - accuracy: 0.7083 - 7ms/epoch - 7ms/step\n",
            "Epoch 205/500\n",
            "1/1 - 0s - loss: 1.4844 - accuracy: 0.7083 - 6ms/epoch - 6ms/step\n",
            "Epoch 206/500\n",
            "1/1 - 0s - loss: 1.4723 - accuracy: 0.7083 - 7ms/epoch - 7ms/step\n",
            "Epoch 207/500\n",
            "1/1 - 0s - loss: 1.4602 - accuracy: 0.7083 - 4ms/epoch - 4ms/step\n",
            "Epoch 208/500\n",
            "1/1 - 0s - loss: 1.4481 - accuracy: 0.7083 - 6ms/epoch - 6ms/step\n",
            "Epoch 209/500\n",
            "1/1 - 0s - loss: 1.4360 - accuracy: 0.7083 - 13ms/epoch - 13ms/step\n",
            "Epoch 210/500\n",
            "1/1 - 0s - loss: 1.4240 - accuracy: 0.7083 - 9ms/epoch - 9ms/step\n",
            "Epoch 211/500\n",
            "1/1 - 0s - loss: 1.4120 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
            "Epoch 212/500\n",
            "1/1 - 0s - loss: 1.4001 - accuracy: 0.7917 - 5ms/epoch - 5ms/step\n",
            "Epoch 213/500\n",
            "1/1 - 0s - loss: 1.3881 - accuracy: 0.7917 - 8ms/epoch - 8ms/step\n",
            "Epoch 214/500\n",
            "1/1 - 0s - loss: 1.3763 - accuracy: 0.7917 - 8ms/epoch - 8ms/step\n",
            "Epoch 215/500\n",
            "1/1 - 0s - loss: 1.3644 - accuracy: 0.7917 - 8ms/epoch - 8ms/step\n",
            "Epoch 216/500\n",
            "1/1 - 0s - loss: 1.3526 - accuracy: 0.7917 - 8ms/epoch - 8ms/step\n",
            "Epoch 217/500\n",
            "1/1 - 0s - loss: 1.3408 - accuracy: 0.7917 - 7ms/epoch - 7ms/step\n",
            "Epoch 218/500\n",
            "1/1 - 0s - loss: 1.3291 - accuracy: 0.7917 - 8ms/epoch - 8ms/step\n",
            "Epoch 219/500\n",
            "1/1 - 0s - loss: 1.3174 - accuracy: 0.7917 - 9ms/epoch - 9ms/step\n",
            "Epoch 220/500\n",
            "1/1 - 0s - loss: 1.3058 - accuracy: 0.7917 - 5ms/epoch - 5ms/step\n",
            "Epoch 221/500\n",
            "1/1 - 0s - loss: 1.2942 - accuracy: 0.7917 - 8ms/epoch - 8ms/step\n",
            "Epoch 222/500\n",
            "1/1 - 0s - loss: 1.2826 - accuracy: 0.7917 - 9ms/epoch - 9ms/step\n",
            "Epoch 223/500\n",
            "1/1 - 0s - loss: 1.2712 - accuracy: 0.7917 - 11ms/epoch - 11ms/step\n",
            "Epoch 224/500\n",
            "1/1 - 0s - loss: 1.2597 - accuracy: 0.7917 - 10ms/epoch - 10ms/step\n",
            "Epoch 225/500\n",
            "1/1 - 0s - loss: 1.2483 - accuracy: 0.8333 - 9ms/epoch - 9ms/step\n",
            "Epoch 226/500\n",
            "1/1 - 0s - loss: 1.2370 - accuracy: 0.8333 - 5ms/epoch - 5ms/step\n",
            "Epoch 227/500\n",
            "1/1 - 0s - loss: 1.2257 - accuracy: 0.8333 - 8ms/epoch - 8ms/step\n",
            "Epoch 228/500\n",
            "1/1 - 0s - loss: 1.2144 - accuracy: 0.8333 - 14ms/epoch - 14ms/step\n",
            "Epoch 229/500\n",
            "1/1 - 0s - loss: 1.2032 - accuracy: 0.8333 - 10ms/epoch - 10ms/step\n",
            "Epoch 230/500\n",
            "1/1 - 0s - loss: 1.1921 - accuracy: 0.8333 - 4ms/epoch - 4ms/step\n",
            "Epoch 231/500\n",
            "1/1 - 0s - loss: 1.1811 - accuracy: 0.8333 - 6ms/epoch - 6ms/step\n",
            "Epoch 232/500\n",
            "1/1 - 0s - loss: 1.1701 - accuracy: 0.8333 - 6ms/epoch - 6ms/step\n",
            "Epoch 233/500\n",
            "1/1 - 0s - loss: 1.1591 - accuracy: 0.8333 - 5ms/epoch - 5ms/step\n",
            "Epoch 234/500\n",
            "1/1 - 0s - loss: 1.1482 - accuracy: 0.8333 - 8ms/epoch - 8ms/step\n",
            "Epoch 235/500\n",
            "1/1 - 0s - loss: 1.1374 - accuracy: 0.8333 - 5ms/epoch - 5ms/step\n",
            "Epoch 236/500\n",
            "1/1 - 0s - loss: 1.1267 - accuracy: 0.8333 - 6ms/epoch - 6ms/step\n",
            "Epoch 237/500\n",
            "1/1 - 0s - loss: 1.1160 - accuracy: 0.8333 - 8ms/epoch - 8ms/step\n",
            "Epoch 238/500\n",
            "1/1 - 0s - loss: 1.1053 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 239/500\n",
            "1/1 - 0s - loss: 1.0948 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 240/500\n",
            "1/1 - 0s - loss: 1.0843 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 241/500\n",
            "1/1 - 0s - loss: 1.0739 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 242/500\n",
            "1/1 - 0s - loss: 1.0635 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 243/500\n",
            "1/1 - 0s - loss: 1.0533 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 244/500\n",
            "1/1 - 0s - loss: 1.0431 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 245/500\n",
            "1/1 - 0s - loss: 1.0329 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 246/500\n",
            "1/1 - 0s - loss: 1.0229 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 247/500\n",
            "1/1 - 0s - loss: 1.0129 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 248/500\n",
            "1/1 - 0s - loss: 1.0030 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 249/500\n",
            "1/1 - 0s - loss: 0.9931 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 250/500\n",
            "1/1 - 0s - loss: 0.9834 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 251/500\n",
            "1/1 - 0s - loss: 0.9737 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 252/500\n",
            "1/1 - 0s - loss: 0.9641 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 253/500\n",
            "1/1 - 0s - loss: 0.9545 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 254/500\n",
            "1/1 - 0s - loss: 0.9451 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 255/500\n",
            "1/1 - 0s - loss: 0.9357 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 256/500\n",
            "1/1 - 0s - loss: 0.9264 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 257/500\n",
            "1/1 - 0s - loss: 0.9172 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 258/500\n",
            "1/1 - 0s - loss: 0.9080 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 259/500\n",
            "1/1 - 0s - loss: 0.8989 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 260/500\n",
            "1/1 - 0s - loss: 0.8899 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 261/500\n",
            "1/1 - 0s - loss: 0.8810 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 262/500\n",
            "1/1 - 0s - loss: 0.8722 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 263/500\n",
            "1/1 - 0s - loss: 0.8634 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 264/500\n",
            "1/1 - 0s - loss: 0.8547 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 265/500\n",
            "1/1 - 0s - loss: 0.8461 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 266/500\n",
            "1/1 - 0s - loss: 0.8376 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 267/500\n",
            "1/1 - 0s - loss: 0.8292 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 268/500\n",
            "1/1 - 0s - loss: 0.8208 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 269/500\n",
            "1/1 - 0s - loss: 0.8125 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 270/500\n",
            "1/1 - 0s - loss: 0.8043 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 271/500\n",
            "1/1 - 0s - loss: 0.7962 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 272/500\n",
            "1/1 - 0s - loss: 0.7882 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 273/500\n",
            "1/1 - 0s - loss: 0.7802 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 274/500\n",
            "1/1 - 0s - loss: 0.7724 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 275/500\n",
            "1/1 - 0s - loss: 0.7646 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 276/500\n",
            "1/1 - 0s - loss: 0.7568 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 277/500\n",
            "1/1 - 0s - loss: 0.7492 - accuracy: 0.8750 - 13ms/epoch - 13ms/step\n",
            "Epoch 278/500\n",
            "1/1 - 0s - loss: 0.7417 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 279/500\n",
            "1/1 - 0s - loss: 0.7342 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 280/500\n",
            "1/1 - 0s - loss: 0.7268 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 281/500\n",
            "1/1 - 0s - loss: 0.7195 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 282/500\n",
            "1/1 - 0s - loss: 0.7122 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 283/500\n",
            "1/1 - 0s - loss: 0.7051 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 284/500\n",
            "1/1 - 0s - loss: 0.6980 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 285/500\n",
            "1/1 - 0s - loss: 0.6910 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 286/500\n",
            "1/1 - 0s - loss: 0.6841 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 287/500\n",
            "1/1 - 0s - loss: 0.6773 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 288/500\n",
            "1/1 - 0s - loss: 0.6705 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 289/500\n",
            "1/1 - 0s - loss: 0.6638 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 290/500\n",
            "1/1 - 0s - loss: 0.6573 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 291/500\n",
            "1/1 - 0s - loss: 0.6507 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 292/500\n",
            "1/1 - 0s - loss: 0.6443 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 293/500\n",
            "1/1 - 0s - loss: 0.6379 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 294/500\n",
            "1/1 - 0s - loss: 0.6317 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 295/500\n",
            "1/1 - 0s - loss: 0.6255 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 296/500\n",
            "1/1 - 0s - loss: 0.6193 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 297/500\n",
            "1/1 - 0s - loss: 0.6133 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 298/500\n",
            "1/1 - 0s - loss: 0.6073 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 299/500\n",
            "1/1 - 0s - loss: 0.6014 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 300/500\n",
            "1/1 - 0s - loss: 0.5956 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 301/500\n",
            "1/1 - 0s - loss: 0.5899 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 302/500\n",
            "1/1 - 0s - loss: 0.5842 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 303/500\n",
            "1/1 - 0s - loss: 0.5786 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 304/500\n",
            "1/1 - 0s - loss: 0.5731 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 305/500\n",
            "1/1 - 0s - loss: 0.5677 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 306/500\n",
            "1/1 - 0s - loss: 0.5623 - accuracy: 0.8750 - 13ms/epoch - 13ms/step\n",
            "Epoch 307/500\n",
            "1/1 - 0s - loss: 0.5570 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 308/500\n",
            "1/1 - 0s - loss: 0.5518 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 309/500\n",
            "1/1 - 0s - loss: 0.5467 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 310/500\n",
            "1/1 - 0s - loss: 0.5416 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 311/500\n",
            "1/1 - 0s - loss: 0.5366 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 312/500\n",
            "1/1 - 0s - loss: 0.5317 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 313/500\n",
            "1/1 - 0s - loss: 0.5268 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 314/500\n",
            "1/1 - 0s - loss: 0.5220 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 315/500\n",
            "1/1 - 0s - loss: 0.5173 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 316/500\n",
            "1/1 - 0s - loss: 0.5127 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 317/500\n",
            "1/1 - 0s - loss: 0.5081 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 318/500\n",
            "1/1 - 0s - loss: 0.5036 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 319/500\n",
            "1/1 - 0s - loss: 0.4991 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 320/500\n",
            "1/1 - 0s - loss: 0.4947 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 321/500\n",
            "1/1 - 0s - loss: 0.4904 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 322/500\n",
            "1/1 - 0s - loss: 0.4862 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 323/500\n",
            "1/1 - 0s - loss: 0.4820 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 324/500\n",
            "1/1 - 0s - loss: 0.4779 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 325/500\n",
            "1/1 - 0s - loss: 0.4738 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 326/500\n",
            "1/1 - 0s - loss: 0.4698 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 327/500\n",
            "1/1 - 0s - loss: 0.4659 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 328/500\n",
            "1/1 - 0s - loss: 0.4620 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 329/500\n",
            "1/1 - 0s - loss: 0.4582 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 330/500\n",
            "1/1 - 0s - loss: 0.4544 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 331/500\n",
            "1/1 - 0s - loss: 0.4508 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 332/500\n",
            "1/1 - 0s - loss: 0.4471 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 333/500\n",
            "1/1 - 0s - loss: 0.4436 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 334/500\n",
            "1/1 - 0s - loss: 0.4400 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 335/500\n",
            "1/1 - 0s - loss: 0.4366 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 336/500\n",
            "1/1 - 0s - loss: 0.4332 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 337/500\n",
            "1/1 - 0s - loss: 0.4298 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 338/500\n",
            "1/1 - 0s - loss: 0.4265 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 339/500\n",
            "1/1 - 0s - loss: 0.4233 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 340/500\n",
            "1/1 - 0s - loss: 0.4201 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 341/500\n",
            "1/1 - 0s - loss: 0.4170 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 342/500\n",
            "1/1 - 0s - loss: 0.4139 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 343/500\n",
            "1/1 - 0s - loss: 0.4108 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 344/500\n",
            "1/1 - 0s - loss: 0.4079 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 345/500\n",
            "1/1 - 0s - loss: 0.4049 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 346/500\n",
            "1/1 - 0s - loss: 0.4020 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 347/500\n",
            "1/1 - 0s - loss: 0.3992 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 348/500\n",
            "1/1 - 0s - loss: 0.3964 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 349/500\n",
            "1/1 - 0s - loss: 0.3937 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 350/500\n",
            "1/1 - 0s - loss: 0.3910 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 351/500\n",
            "1/1 - 0s - loss: 0.3883 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 352/500\n",
            "1/1 - 0s - loss: 0.3857 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 353/500\n",
            "1/1 - 0s - loss: 0.3832 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 354/500\n",
            "1/1 - 0s - loss: 0.3806 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 355/500\n",
            "1/1 - 0s - loss: 0.3782 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 356/500\n",
            "1/1 - 0s - loss: 0.3757 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 357/500\n",
            "1/1 - 0s - loss: 0.3733 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 358/500\n",
            "1/1 - 0s - loss: 0.3710 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 359/500\n",
            "1/1 - 0s - loss: 0.3687 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 360/500\n",
            "1/1 - 0s - loss: 0.3664 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 361/500\n",
            "1/1 - 0s - loss: 0.3642 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 362/500\n",
            "1/1 - 0s - loss: 0.3620 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 363/500\n",
            "1/1 - 0s - loss: 0.3598 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 364/500\n",
            "1/1 - 0s - loss: 0.3577 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 365/500\n",
            "1/1 - 0s - loss: 0.3556 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 366/500\n",
            "1/1 - 0s - loss: 0.3536 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 367/500\n",
            "1/1 - 0s - loss: 0.3516 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 368/500\n",
            "1/1 - 0s - loss: 0.3496 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 369/500\n",
            "1/1 - 0s - loss: 0.3476 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 370/500\n",
            "1/1 - 0s - loss: 0.3457 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 371/500\n",
            "1/1 - 0s - loss: 0.3438 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 372/500\n",
            "1/1 - 0s - loss: 0.3420 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 373/500\n",
            "1/1 - 0s - loss: 0.3402 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 374/500\n",
            "1/1 - 0s - loss: 0.3384 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 375/500\n",
            "1/1 - 0s - loss: 0.3366 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 376/500\n",
            "1/1 - 0s - loss: 0.3349 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 377/500\n",
            "1/1 - 0s - loss: 0.3332 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 378/500\n",
            "1/1 - 0s - loss: 0.3315 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 379/500\n",
            "1/1 - 0s - loss: 0.3299 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 380/500\n",
            "1/1 - 0s - loss: 0.3283 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 381/500\n",
            "1/1 - 0s - loss: 0.3267 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 382/500\n",
            "1/1 - 0s - loss: 0.3251 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 383/500\n",
            "1/1 - 0s - loss: 0.3236 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 384/500\n",
            "1/1 - 0s - loss: 0.3221 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 385/500\n",
            "1/1 - 0s - loss: 0.3206 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 386/500\n",
            "1/1 - 0s - loss: 0.3191 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 387/500\n",
            "1/1 - 0s - loss: 0.3177 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 388/500\n",
            "1/1 - 0s - loss: 0.3163 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 389/500\n",
            "1/1 - 0s - loss: 0.3149 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 390/500\n",
            "1/1 - 0s - loss: 0.3135 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 391/500\n",
            "1/1 - 0s - loss: 0.3122 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 392/500\n",
            "1/1 - 0s - loss: 0.3109 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 393/500\n",
            "1/1 - 0s - loss: 0.3096 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 394/500\n",
            "1/1 - 0s - loss: 0.3083 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 395/500\n",
            "1/1 - 0s - loss: 0.3070 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 396/500\n",
            "1/1 - 0s - loss: 0.3058 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 397/500\n",
            "1/1 - 0s - loss: 0.3046 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 398/500\n",
            "1/1 - 0s - loss: 0.3034 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 399/500\n",
            "1/1 - 0s - loss: 0.3022 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 400/500\n",
            "1/1 - 0s - loss: 0.3010 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 401/500\n",
            "1/1 - 0s - loss: 0.2999 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 402/500\n",
            "1/1 - 0s - loss: 0.2988 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 403/500\n",
            "1/1 - 0s - loss: 0.2976 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 404/500\n",
            "1/1 - 0s - loss: 0.2966 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 405/500\n",
            "1/1 - 0s - loss: 0.2955 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 406/500\n",
            "1/1 - 0s - loss: 0.2944 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 407/500\n",
            "1/1 - 0s - loss: 0.2934 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 408/500\n",
            "1/1 - 0s - loss: 0.2924 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 409/500\n",
            "1/1 - 0s - loss: 0.2914 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 410/500\n",
            "1/1 - 0s - loss: 0.2904 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 411/500\n",
            "1/1 - 0s - loss: 0.2894 - accuracy: 0.8750 - 12ms/epoch - 12ms/step\n",
            "Epoch 412/500\n",
            "1/1 - 0s - loss: 0.2884 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 413/500\n",
            "1/1 - 0s - loss: 0.2875 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 414/500\n",
            "1/1 - 0s - loss: 0.2865 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 415/500\n",
            "1/1 - 0s - loss: 0.2856 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 416/500\n",
            "1/1 - 0s - loss: 0.2847 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 417/500\n",
            "1/1 - 0s - loss: 0.2838 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 418/500\n",
            "1/1 - 0s - loss: 0.2829 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 419/500\n",
            "1/1 - 0s - loss: 0.2821 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 420/500\n",
            "1/1 - 0s - loss: 0.2812 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 421/500\n",
            "1/1 - 0s - loss: 0.2804 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 422/500\n",
            "1/1 - 0s - loss: 0.2796 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 423/500\n",
            "1/1 - 0s - loss: 0.2787 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 424/500\n",
            "1/1 - 0s - loss: 0.2779 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 425/500\n",
            "1/1 - 0s - loss: 0.2771 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 426/500\n",
            "1/1 - 0s - loss: 0.2764 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 427/500\n",
            "1/1 - 0s - loss: 0.2756 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 428/500\n",
            "1/1 - 0s - loss: 0.2748 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 429/500\n",
            "1/1 - 0s - loss: 0.2741 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 430/500\n",
            "1/1 - 0s - loss: 0.2733 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 431/500\n",
            "1/1 - 0s - loss: 0.2726 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 432/500\n",
            "1/1 - 0s - loss: 0.2719 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 433/500\n",
            "1/1 - 0s - loss: 0.2712 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 434/500\n",
            "1/1 - 0s - loss: 0.2705 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 435/500\n",
            "1/1 - 0s - loss: 0.2698 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 436/500\n",
            "1/1 - 0s - loss: 0.2691 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 437/500\n",
            "1/1 - 0s - loss: 0.2685 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 438/500\n",
            "1/1 - 0s - loss: 0.2678 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 439/500\n",
            "1/1 - 0s - loss: 0.2672 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 440/500\n",
            "1/1 - 0s - loss: 0.2665 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 441/500\n",
            "1/1 - 0s - loss: 0.2659 - accuracy: 0.8750 - 13ms/epoch - 13ms/step\n",
            "Epoch 442/500\n",
            "1/1 - 0s - loss: 0.2653 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 443/500\n",
            "1/1 - 0s - loss: 0.2646 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 444/500\n",
            "1/1 - 0s - loss: 0.2640 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 445/500\n",
            "1/1 - 0s - loss: 0.2634 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 446/500\n",
            "1/1 - 0s - loss: 0.2628 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 447/500\n",
            "1/1 - 0s - loss: 0.2623 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 448/500\n",
            "1/1 - 0s - loss: 0.2617 - accuracy: 0.8750 - 4ms/epoch - 4ms/step\n",
            "Epoch 449/500\n",
            "1/1 - 0s - loss: 0.2611 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 450/500\n",
            "1/1 - 0s - loss: 0.2605 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 451/500\n",
            "1/1 - 0s - loss: 0.2600 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 452/500\n",
            "1/1 - 0s - loss: 0.2594 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 453/500\n",
            "1/1 - 0s - loss: 0.2589 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 454/500\n",
            "1/1 - 0s - loss: 0.2584 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 455/500\n",
            "1/1 - 0s - loss: 0.2578 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 456/500\n",
            "1/1 - 0s - loss: 0.2573 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 457/500\n",
            "1/1 - 0s - loss: 0.2568 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 458/500\n",
            "1/1 - 0s - loss: 0.2563 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 459/500\n",
            "1/1 - 0s - loss: 0.2558 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 460/500\n",
            "1/1 - 0s - loss: 0.2553 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 461/500\n",
            "1/1 - 0s - loss: 0.2548 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 462/500\n",
            "1/1 - 0s - loss: 0.2543 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 463/500\n",
            "1/1 - 0s - loss: 0.2539 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 464/500\n",
            "1/1 - 0s - loss: 0.2534 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 465/500\n",
            "1/1 - 0s - loss: 0.2529 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 466/500\n",
            "1/1 - 0s - loss: 0.2525 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 467/500\n",
            "1/1 - 0s - loss: 0.2520 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 468/500\n",
            "1/1 - 0s - loss: 0.2516 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 469/500\n",
            "1/1 - 0s - loss: 0.2511 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 470/500\n",
            "1/1 - 0s - loss: 0.2507 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 471/500\n",
            "1/1 - 0s - loss: 0.2503 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 472/500\n",
            "1/1 - 0s - loss: 0.2498 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 473/500\n",
            "1/1 - 0s - loss: 0.2494 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 474/500\n",
            "1/1 - 0s - loss: 0.2490 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 475/500\n",
            "1/1 - 0s - loss: 0.2486 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 476/500\n",
            "1/1 - 0s - loss: 0.2482 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 477/500\n",
            "1/1 - 0s - loss: 0.2478 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 478/500\n",
            "1/1 - 0s - loss: 0.2474 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 479/500\n",
            "1/1 - 0s - loss: 0.2470 - accuracy: 0.8750 - 11ms/epoch - 11ms/step\n",
            "Epoch 480/500\n",
            "1/1 - 0s - loss: 0.2466 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 481/500\n",
            "1/1 - 0s - loss: 0.2462 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 482/500\n",
            "1/1 - 0s - loss: 0.2459 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 483/500\n",
            "1/1 - 0s - loss: 0.2455 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 484/500\n",
            "1/1 - 0s - loss: 0.2451 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 485/500\n",
            "1/1 - 0s - loss: 0.2447 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 486/500\n",
            "1/1 - 0s - loss: 0.2444 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 487/500\n",
            "1/1 - 0s - loss: 0.2440 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 488/500\n",
            "1/1 - 0s - loss: 0.2437 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 489/500\n",
            "1/1 - 0s - loss: 0.2433 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 490/500\n",
            "1/1 - 0s - loss: 0.2430 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 491/500\n",
            "1/1 - 0s - loss: 0.2426 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Epoch 492/500\n",
            "1/1 - 0s - loss: 0.2423 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 493/500\n",
            "1/1 - 0s - loss: 0.2420 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 494/500\n",
            "1/1 - 0s - loss: 0.2416 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 495/500\n",
            "1/1 - 0s - loss: 0.2413 - accuracy: 0.8750 - 9ms/epoch - 9ms/step\n",
            "Epoch 496/500\n",
            "1/1 - 0s - loss: 0.2410 - accuracy: 0.8750 - 10ms/epoch - 10ms/step\n",
            "Epoch 497/500\n",
            "1/1 - 0s - loss: 0.2407 - accuracy: 0.8750 - 7ms/epoch - 7ms/step\n",
            "Epoch 498/500\n",
            "1/1 - 0s - loss: 0.2403 - accuracy: 0.8750 - 6ms/epoch - 6ms/step\n",
            "Epoch 499/500\n",
            "1/1 - 0s - loss: 0.2400 - accuracy: 0.8750 - 8ms/epoch - 8ms/step\n",
            "Epoch 500/500\n",
            "1/1 - 0s - loss: 0.2397 - accuracy: 0.8750 - 5ms/epoch - 5ms/step\n",
            "Jack and jill came tumbling after pail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1HXvt08xOEUciBzjpZl_0K7KuWL-zUuhq)"
      ],
      "metadata": {
        "id": "kcb2MceTdnyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jTQc4MUzdhLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QZQTV0IBcMm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wadJAfCIb-_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vAZIDXLZQQdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9hJX88ewQQpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TvEbq_C6QQzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hy-ukSPAQQ-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "92Qa4eFcQRIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}